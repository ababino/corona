{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO Regresion on covid-19 cases in New York, Massachusetts and Connecticut\n",
    "\n",
    "## Load modulues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import requests\n",
    "import urllib.parse\n",
    "from zipfile import ZipFile\n",
    "import io\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from sklearn import linear_model\n",
    "from scipy import stats as sps\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from IPython.display import display\n",
    "\n",
    "locator = mdates.AutoDateLocator()\n",
    "\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "GAMMA = 1/7.5\n",
    "\n",
    "events = {}\n",
    "\n",
    "df_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "### New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tests</th>\n",
       "      <th>Positives</th>\n",
       "      <th>Odds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-11</th>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>20463</td>\n",
       "      <td>1430</td>\n",
       "      <td>0.075133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-12</th>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>33794</td>\n",
       "      <td>2176</td>\n",
       "      <td>0.068822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-13</th>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>39850</td>\n",
       "      <td>2390</td>\n",
       "      <td>0.063801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-14</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>39291</td>\n",
       "      <td>2762</td>\n",
       "      <td>0.075611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-15</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>40669</td>\n",
       "      <td>2419</td>\n",
       "      <td>0.063242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  Tests  Positives      Odds\n",
       "date                                             \n",
       "2020-05-11 2020-05-11  20463       1430  0.075133\n",
       "2020-05-12 2020-05-12  33794       2176  0.068822\n",
       "2020-05-13 2020-05-13  39850       2390  0.063801\n",
       "2020-05-14 2020-05-14  39291       2762  0.075611\n",
       "2020-05-15 2020-05-15  40669       2419  0.063242"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsname = 'New York'\n",
    "\n",
    "# API information\n",
    "# https://health.data.ny.gov/Health/New-York-State-Statewide-COVID-19-Testing/xdss-u53e\n",
    "\n",
    "if not os.path.isfile('data/ny.csv'):\n",
    "    url = urllib.parse.quote(\"https://health.data.ny.gov/resource/xdss-u53e.csv/?$limit=5000\")\n",
    "    #\n",
    "    dfs = []\n",
    "    offset = 0\n",
    "    while offset >=0:\n",
    "        url = \"https://health.data.ny.gov/resource/xdss-u53e.csv/?$limit=5000&$offset={}\".format(offset)\n",
    "        df = pd.read_csv(url, usecols=['test_date', 'total_number_of_tests', 'new_positives'])\n",
    "        dfs.append(df)\n",
    "        if len(df)==5000:\n",
    "            offset += 5000 \n",
    "        else:\n",
    "            offset = -1\n",
    "    dfraw = pd.concat(dfs)\n",
    "    #'test_date=2020-03-15T00:00:00.000'\n",
    "\n",
    "    dfraw = dfraw.rename(columns={'new_positives': 'Positives', 'total_number_of_tests': 'Tests', 'test_date': 'date'})\n",
    "    print(len(dfraw))\n",
    "    dfraw['date'] = pd.to_datetime(dfraw['date'])\n",
    "    #counties = (df.groupby('date')['Tests']>0).count()\n",
    "    df = dfraw.groupby('date').sum()\n",
    "    print(df.head(1))\n",
    "    df['Odds'] = df.Positives / (df.Tests - df.Positives)\n",
    "    df['Date'] = pd.to_datetime(df.index)\n",
    "    df.to_csv('data/ny.csv')\n",
    "    df = df[df['Date'] >= '2020-03-15']\n",
    "    # last date of full NYS PAUSE\n",
    "    df = df[df['Date'] <= '2020-05-15']\n",
    "\n",
    "else:\n",
    "    df = pd.read_csv('data/ny.csv')\n",
    "    df['date'] =pd.to_datetime(df['date'])\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.set_index('date')\n",
    "    df = df[df['Date'] >= '2020-03-15']\n",
    "    # last date of full NYS PAUSE\n",
    "    df = df[df['Date'] <= '2020-05-15']\n",
    "df = df[['Date', 'Tests', 'Positives', 'Odds']]\n",
    "df_dict[dsname] = df\n",
    "\n",
    "# 03/17/2020 close of gyms, restaurants and bars, movie theaters, mass gathering up to 50. https://www.governor.ny.gov/news/amid-lack-federal-direction-governor-cuomo-governor-murphy-and-governor-lamont-announce\n",
    "bars = pd.to_datetime('03-16-2020 20:00', dayfirst=False)\n",
    "# 03/18/2020 school clousure http://www.nysed.gov/news/2020/state-education-department-issues-updated-guidance-schools-regarding-novel-coronavirus\n",
    "schools = pd.to_datetime('03-18-2020 20:00', dayfirst=False)\n",
    "\n",
    "# https://www.governor.ny.gov/news/amid-ongoing-covid-19-pandemic-governor-cuomo-announces-deployment-1000-bed-hospital-ship-usns\n",
    "# 03/20/2020 00:00 50% of the workforce\n",
    "workforce_50 = pd.to_datetime('03-20-2020 20:00', dayfirst=False)\n",
    "# 03/22/2020 20:00 ny_pause \n",
    "ny_pause = pd.to_datetime('22-03-2020 00:00', dayfirst=True)\n",
    "# CDC masks https://www.npr.org/sections/goatsandsoda/2020/04/10/829890635/why-there-so-many-different-guidelines-for-face-masks-for-the-public\n",
    "masks_cdc = pd.to_datetime('03-04-2020 00:00', dayfirst=True)\n",
    "mask_employers = pd.to_datetime('12-04-2020 00:00', dayfirst=True)\n",
    "mask_public = pd.to_datetime('17-04-2020 00:00', dayfirst=True)\n",
    "\n",
    "events_list = [bars, schools, workforce_50, ny_pause, masks_cdc, mask_employers, mask_public]\n",
    "events['New York'] = events_list\n",
    "\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecticut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tests</th>\n",
       "      <th>Positives</th>\n",
       "      <th>Odds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-15</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>7400</td>\n",
       "      <td>592</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-16</th>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>3607</td>\n",
       "      <td>281</td>\n",
       "      <td>0.084486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-17</th>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>2627</td>\n",
       "      <td>208</td>\n",
       "      <td>0.085986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-18</th>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>6541</td>\n",
       "      <td>661</td>\n",
       "      <td>0.112415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-19</th>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>6717</td>\n",
       "      <td>750</td>\n",
       "      <td>0.125691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  Tests  Positives      Odds\n",
       "date                                             \n",
       "2020-05-15 2020-05-15   7400        592  0.086957\n",
       "2020-05-16 2020-05-16   3607        281  0.084486\n",
       "2020-05-17 2020-05-17   2627        208  0.085986\n",
       "2020-05-18 2020-05-18   6541        661  0.112415\n",
       "2020-05-19 2020-05-19   6717        750  0.125691"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsname = 'Connecticut'\n",
    "# reopening phase 1 may 20\n",
    "# https://portal.ct.gov/Coronavirus/Covid-19-Knowledge-Base/Reopen-plan\n",
    "\n",
    "# all APIs avaliables\n",
    "# https://data.ct.gov/stories/s/COVID-19-data/wa3g-tfvc/#covid-19-testing-data\n",
    "\n",
    "if not os.path.isfile('data/connecticut.csv'):\n",
    "    dfs = []\n",
    "    offset = 0\n",
    "    while offset >=0:\n",
    "        url = 'https://data.ct.gov/resource/qfkt-uahj.csv?$limit=5000&$offset={}'.format(offset)\n",
    "        df = pd.read_csv(url)\n",
    "        dfs.append(df)\n",
    "        if len(df)==5000:\n",
    "            offset += 5000 \n",
    "        else:\n",
    "            offset = -1\n",
    "    dfcounty = pd.concat(dfs)\n",
    "    dfcounty = dfcounty.rename(columns={'number_of_positives': 'Positives', 'number_of_tests': 'Tests', 'number_of_negatives': 'Negatives'})\n",
    "    dfcounty['Tests'] = dfcounty['Tests'] - dfcounty['number_of_indeterminates']\n",
    "    # print(len(dfcounty))\n",
    "    dfcounty['date'] = pd.to_datetime(dfcounty['date'])\n",
    "    df = dfcounty.groupby('date').sum()\n",
    "    #df = df.diff()\n",
    "    df['Odds'] = df.Positives / df.Negatives\n",
    "    df['Date'] = pd.to_datetime(df.index)\n",
    "    df.to_csv('data/connecticut.csv')\n",
    "else:\n",
    "    df = pd.read_csv('data/connecticut.csv')\n",
    "    df = df.set_index('date')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.sort_index()\n",
    "#print(df[['Tests', 'Positives', 'Odds']].head(30))\n",
    "\n",
    "df = df[df['Date'] <= '2020-05-19']\n",
    "df = df[df['Date'] > '2020-03-19']\n",
    "df = df[['Date', 'Tests', 'Positives', 'Odds']]\n",
    "#print(df.head())\n",
    "df_dict[dsname] = df\n",
    "# intervention dates\n",
    "# https://portal.ct.gov/Coronavirus/Pages/Emergency-Orders-issued-by-the-Governor-and-State-Agencies\n",
    "# 03/12/2020 no gatherings with more than 250\n",
    "large_gatherings = pd.to_datetime('03-12-2020 00:00', dayfirst=False)\n",
    "schools = pd.to_datetime('03-17-2020 00:00', dayfirst=False)\n",
    "bars = pd.to_datetime('03-16-2020 20:00', dayfirst=False)\n",
    "\n",
    "malls = pd.to_datetime('03-19-2020 20:00', dayfirst=False)\n",
    "workforce100 = pd.to_datetime('03-23-2020 20:00', dayfirst=False)\n",
    "# CDC masks https://www.npr.org/sections/goatsandsoda/2020/04/10/829890635/why-there-so-many-different-guidelines-for-face-masks-for-the-public\n",
    "masks_cdc = pd.to_datetime('04-03-2020 00:00', dayfirst=False)\n",
    "mask_public = pd.to_datetime('04-20-2020 00:00', dayfirst=False)\n",
    "\n",
    "event_list = [large_gatherings, bars, schools, malls, workforce100, masks_cdc,  mask_public]\n",
    "events[dsname] = event_list\n",
    "\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massachusetts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname = 'Massachusetts'\n",
    "# web site with data\n",
    "# https://www.mass.gov/info-details/covid-19-response-reporting\n",
    "yesterday = datetime.today() - timedelta(0)\n",
    "if  not os.path.isfile('data/massachusetts.csv'):\n",
    "    #yesterday = datetime.today() - timedelta(10)\n",
    "    yesterday_str = datetime.strftime(yesterday, '%B-%d-%Y').lower()\n",
    "    fn = 'data/{}.zip'.format(dsname)\n",
    "    \n",
    "    url2 = 'https://www.mass.gov/doc/covid-19-raw-data-june-10-2020/download'\n",
    "    url = 'https://www.mass.gov/doc/covid-19-raw-data-{}/download'.format(yesterday_str)\n",
    "    print(url)\n",
    "    print(url2)\n",
    "    myfile = requests.get(url, allow_redirects=True)\n",
    "    #open(fn, 'wb').write(myfile.content)\n",
    "    zf = ZipFile(io.BytesIO(myfile.content))\n",
    "    csvf = zf.open('TestingByDate.csv')\n",
    "    df = pd.read_csv(csvf)\n",
    "\n",
    "    # https://www.mass.gov/doc/covid-19-raw-data-may-27-2020/download\n",
    "    #df = pd.read_csv('data/massachusetts/COVID-19-Dashboard-Files-05-24-2020/TestingByDate.csv',\n",
    "    #                 usecols=['Date', 'New', 'Positive'])\n",
    "\n",
    "    df = df.rename(columns={'Molecular Positive New': 'Positives', 'Molecular New': 'Tests'})\n",
    "    df['Negatives'] = df.Tests - df.Positives\n",
    "    df = df.query('Tests>100')\n",
    "    df['date'] = pd.to_datetime(df['Date'])\n",
    "    df= df.set_index('date')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Odds'] = df.Positives / df.Negatives\n",
    "    #df = df[df['Date']<'2020-05-15']\n",
    "    df.to_csv('data/massachusetts.csv')\n",
    "else:\n",
    "    df = pd.read_csv('data/massachusetts.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.set_index('date')\n",
    "df = df[df['Date']<'2020-05-18']\n",
    "#df = df[df['Date']>'2020-03-15']\n",
    "df = df[df['Date']>'2020-03-14']\n",
    "df = df[['Date', 'Tests', 'Positives', 'Odds']]\n",
    "df_dict[dsname] = df\n",
    "\n",
    "# https://www.mass.gov/info-details/covid-19-state-of-emergency\n",
    "schools = pd.to_datetime('03-22-2020 00:00', dayfirst=False)\n",
    "saty_at_home = pd.to_datetime('03-24-2020 00:00', dayfirst=False)\n",
    "masks_cdc = pd.to_datetime('04-03-2020 00:00', dayfirst=False)\n",
    "masks_public = pd.to_datetime('05-06-2020 00:00', dayfirst=False)\n",
    "\n",
    "event_list = [schools, saty_at_home, masks_cdc, masks_public]\n",
    "events[dsname] = event_list\n",
    "df_dict[dsname] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname = 'Michigan'\n",
    "if not os.path.isfile('data/michigan.csv'):\n",
    "    df = pd.read_excel('https://www.michigan.gov/documents/coronavirus/Diagnostic_Tests_by_Result_and_County_2020-06-16_693915_7.xlsx')\n",
    "    df['date'] = pd.to_datetime(df['MessageDate'])\n",
    "    df = df[df['COUNTY']!='Correctional']\n",
    "    df = df.groupby('date').sum()\n",
    "    df['Date'] = df.index\n",
    "    df.to_csv('data/michigan.csv')\n",
    "else:\n",
    "    df = pd.read_csv('data/michigan.csv', index_col='date', parse_dates=['date', 'Date'])\n",
    "df = df.rename(columns={'Negative': 'Negatives', 'Positive': 'Positives','Total': 'Tests'})\n",
    "df['Odds'] = df.Positives / df.Negatives\n",
    "df = df[df['Date']>'2020-03-16']\n",
    "df = df[df['Date']<'2020-05-18']\n",
    "df_dict[dsname] = df\n",
    "\n",
    "# https://www.michigan.gov/whitmer/0,9309,7-387-90499_90705-522626--,00.html\n",
    "saty_at_home = pd.to_datetime('03-24-2020 00:00', dayfirst=False)\n",
    "masks_cdc = pd.to_datetime('04-03-2020 00:00', dayfirst=False)\n",
    "# https://www.michigan.gov/whitmer/0,9309,7-387-90499-526896--,00.html\n",
    "masks_public = pd.to_datetime('04-24-2020 00:00', dayfirst=False)\n",
    "event_list = [saty_at_home, masks_cdc, masks_public]\n",
    "events[dsname] = event_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname = 'Rhode Island'\n",
    "#https://docs.google.com/spreadsheets/d/1n-zMS9Al94CPj_Tc3K7Adin-tN9x1RSjjx2UzJ4SV7Q/edit#gid=590763272\n",
    "url = 'https://docs.google.com/spreadsheets/d/1n-zMS9Al94CPj_Tc3K7Adin-tN9x1RSjjx2UzJ4SV7Q/export?format=csv&id=1n-zMS9Al94CPj_Tc3K7Adin-tN9x1RSjjx2UzJ4SV7Q&gid=590763272'\n",
    "df  = pd.read_csv(url, \n",
    "                  usecols=['New positive labs', 'New negative labs', 'Date'])\n",
    "#df  = pd.read_csv('data/COVID-19 Rhode Island Data - COVID Trends.csv', \n",
    "#                  usecols=['New positive labs', 'New negative labs', 'Date'])\n",
    "\n",
    "df = df.rename(columns={'New positive labs': 'Positives', 'New negative labs': 'Negatives'})\n",
    "df['Tests'] = df.Positives + df.Negatives\n",
    "df = df.query('Tests>100')\n",
    "df['date'] = pd.to_datetime(df['Date'])\n",
    "df= df.set_index('date')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Odds'] = df.Positives / df.Negatives\n",
    "df = df[df['Date']>='2020-04-01']\n",
    "df = df[df['Date']<'2020-05-18']\n",
    "df_dict[dsname] = df\n",
    "\n",
    "# https://governor.ri.gov/documents/orders/Executive-Order-20-09.pdf\n",
    "bars = pd.to_datetime('03-16-2020 00:00', dayfirst=False)\n",
    "# https://governor.ri.gov/documents/orders/Executive-Order-20-09.pdf\n",
    "public_gatherings = pd.to_datetime('03-22-2020 00:00', dayfirst=False)\n",
    "\n",
    "\n",
    "saty_at_home = pd.to_datetime('03-28-2020 00:00', dayfirst=False)\n",
    "masks_cdc = pd.to_datetime('04-03-2020 00:00', dayfirst=False)\n",
    "masks_at_work = pd.to_datetime('04-14-2020 00:00', dayfirst=False)\n",
    "masks_public = pd.to_datetime('05-05-2020 00:00', dayfirst=False)\n",
    "event_list = [bars, public_gatherings, saty_at_home, masks_cdc,masks_at_work, masks_public]\n",
    "events[dsname] = event_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname = 'Virginia'\n",
    "if not os.path.isfile('data/virginia.csv'):\n",
    "    #df  = pd.read_csv('https://www.vdh.virginia.gov/content/uploads/sites/182/2020/05/VDH-COVID-19-PublicUseDataset-Tests_by-LabReportDate.csv')\n",
    "    df = pd.read_csv('data/VDH-COVID-19-PublicUseDataset-Tests_by-LabReportDate.csv')\n",
    "    df = df.rename(columns={'Number of Positive PCR Tests': 'Positives', 'Number of PCR Testing Encounters': 'Tests'})\n",
    "    df = df[df['Lab Report Date']!='Not Reported']\n",
    "    df['date'] = pd.to_datetime(df['Lab Report Date'])\n",
    "    df = df.groupby('date').sum()\n",
    "    df['Date'] = df.index\n",
    "    df.to_csv('data/virginia.csv')\n",
    "else:\n",
    "    df = pd.read_csv('data/virginia.csv', index_col='date', parse_dates=['date', 'Date'])\n",
    "df = df[['Date', 'Tests', 'Positives']]\n",
    "df['Negatives'] = df.Tests + df.Positives\n",
    "df['Odds'] = df.Positives / df.Negatives\n",
    "df = df[df['Date']>'2020-03-22']\n",
    "\n",
    "# lab report day might be lagging \n",
    "df = df[df['Date']<'2020-05-18']\n",
    "#df = df[df['Date']<datetime.today()-timedelta(7)]\n",
    "df_dict[dsname] = df\n",
    "\n",
    "# https://www.governor.virginia.gov/media/governorvirginiagov/executive-actions/EO-53-Temporary-Restrictions-Due-To-Novel-Coronavirus-(COVID-19).pdf\n",
    "schools = pd.to_datetime('03-13-2020 00:00', dayfirst=False)\n",
    "bars = pd.to_datetime('03-16-2020 00:00', dayfirst=False)\n",
    "# \n",
    "#public_gatherings = pd.to_datetime('03-22-2020 00:00', dayfirst=False)\n",
    "\n",
    "\n",
    "saty_at_home = pd.to_datetime('04-02-2020 00:00', dayfirst=False)\n",
    "masks_cdc = pd.to_datetime('04-03-2020 00:00', dayfirst=False)\n",
    "# https://www.governor.virginia.gov/media/governorvirginiagov/executive-actions/EO-63-and-Order-Of-Public-Health-Emergency-Five---Requirement-To-Wear-Face-Covering-While-Inside-Buildings.pdf\n",
    "masks_indoors = pd.to_datetime('05-29-2020 00:00', dayfirst=False)\n",
    "\n",
    "event_list = [schools, bars, saty_at_home, masks_cdc, masks_indoors]\n",
    "events[dsname] = event_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "I we plot the number of positive tests we can see that the data is noisy.\n",
    "But, if we take into account the number of people tested each day, the data looks way more clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e62e87802b2404c864eb5a1b70847c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close(1)\n",
    "\n",
    "current_palette = sns.color_palette()\n",
    "\n",
    "df = pd.concat(df_dict).reset_index()\n",
    "df = df.rename(columns={'level_0': 'State'})\n",
    "df['Tests (right)'] = df['Tests']\n",
    "g = sns.FacetGrid(df, col='State', col_wrap=2, xlim=[df.Date.min(), df.Date.max()], sharey=False, aspect=1.3, dropna=False)\n",
    "\n",
    "legend_and_hand = []\n",
    "def myplot(data, y=None, secondary_y=None, legend=None, color=None):\n",
    "    ax = data.plot(x='Date', y=y[0], ax=plt.gca(), label=y[0])\n",
    "    legend_and_hand.append(ax.get_legend_handles_labels())\n",
    "    ax = data.plot(x='Date', y=y[1], secondary_y=secondary_y, ax=ax, label=y[1])\n",
    "    legend_and_hand.append(ax.get_legend_handles_labels())\n",
    "    return ax\n",
    "g.map_dataframe(myplot, y=['Positives', 'Tests (right)'], secondary_y=['Tests (right)'])\n",
    "\n",
    "#g.axes[0].xaxis.set_major_locator(locator)\n",
    "#g.axes[0].xaxis.set_major_formatter(formatter)\n",
    "\n",
    "g.add_legend({l[0]: h[0] for h,l in legend_and_hand[:2]}, loc='lower center', bbox_to_anchor=(0.4, 0), ncol=2)\n",
    "g.set_titles('{col_name}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/state_testes.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between the total number of infected individuals and positive tests\n",
    "\n",
    "As has been shown previously [[1]](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0002185), the number of new infected individuals in a given day $k_t$ is given by:\n",
    "$$\n",
    "k_t = k_{t-1} e^{(R_{t-1}-1)\\gamma}\n",
    "$$\n",
    "\n",
    "where $R_t$ is the effective reproductuve number and $\\gamma^{-1}$ is the infectious period estimated as 7 days accoring to [2].\n",
    "\n",
    "The following derivation was suggested to my by Will Meierjurgen Farr on this GitHub [Issue](https://github.com/k-sys/covid-19/issues/45#issuecomment-623782130). \n",
    "Since we do not have access to the total number of infected indiviudals, but only to the population being tested, we have to use some statisticals assumtions on this populations.\n",
    "If we asume that the people being tested, in a given day, is a sample of the population with COVID-19-like sympoms we can state that:\n",
    "\n",
    "$$\n",
    "n_{t} = [P_t(CV|sympoms) P_t(sympoms) +P_t(not CV|sympoms)P_t(sympoms)]Nf_t \n",
    "$$\n",
    "\n",
    "where $n_{t}$ is the number of people tested, $P_t(CV|sympoms)$ is the probablity of a pacient being positive for coronavirus given that the she is sympomatic, $P_t(sympoms)$ is the probablity of having COVID-like sympoms, $P_t(not CV|sympoms)$ is the probability of a pacient being coronavirus negative given he has COVID-19-like sympoms, $N$ is the total population, and $f_t$ is the fraction of people with sympoms that is selected to be tested (this number can be different each day, for example if the number of tests availabes changes).\n",
    "Also, note that the probability of a test being positive in a given day is $Positive_t=P_t(CV|sympoms) P_t(sympoms) N f_t$\n",
    "\n",
    "\n",
    "Now, if we assume that $P_t(sympoms|CV)=cte$ we can use Bayes theorem to show that:\n",
    "\n",
    "$$\n",
    "P_t(CV|sympoms) P_t(sympoms) \\propto P_t(CV) = \\frac{k_t}{N}\n",
    "$$\n",
    "\n",
    "Then:\n",
    "$$\n",
    "P_t(CV|sympoms) P_t(sympoms) \\propto k_t\n",
    "$$\n",
    "\n",
    "Finally, if we assume that $P_t(not CV|sympoms)P_t(sympoms)=cte$:\n",
    "$$\n",
    "Odds_t = \\frac{P(CV|sympoms) P(sympoms)Nf_t}{P_t(not CV|sympoms)P_t(sympoms)Nf_t}\n",
    "$$\n",
    "$$\n",
    "Odds_t = \\frac{P(CV|sympoms) P(sympoms)}{P_t(not CV|sympoms)P_t(sympoms)}\n",
    "$$\n",
    "$$\n",
    "Odds_t \\propto k_t\n",
    "$$\n",
    "\n",
    "\\begin{equation}\n",
    "Odds_t = Odds_{t-1} e^{(R_{t-1}-1)\\gamma} (1)\n",
    "\\end{equation}\n",
    "\n",
    "We used three hypothesis. First, constant population $N$ (for $P_t \\propto k_t$ and for the evolution of $k_t$). Second, that the tested population is a random sample from the population with COVID19-like sympoms ($n_t = [P_t(CV|sympoms) P_t(sympoms) +P_t(not CV|sympoms)P_t(sympoms)]Nf_t$) this is not the case when people is being tested based on contacts for example. And third, that $P_t(not CV|sympoms)P_t(sympoms)=cte$, this is equivalent to say that the number of people with covid-19-like sympoms but without the coronavirus (for example people with the flu) is constant, or at least it changes are negligible compared with the changes in the amount of sympomatic people with coronavirus.\n",
    "\n",
    "## Linearization\n",
    "\n",
    "Defining\n",
    "\n",
    "$$\n",
    "b_i =  e^{(R_{i-1}-1)\\gamma} (2)\n",
    "$$\n",
    "\n",
    "We can write [1] as:\n",
    "\n",
    "\\begin{equation}\n",
    "odd_i = b_{i-1} * odd_{i-1} (3)\n",
    "\\end{equation}\n",
    "\n",
    "Now, instead of using $b_i$ as the parameters to estimate we decompose each $b$ as follows:\n",
    "\n",
    "$$\n",
    "b_i = \\prod_{j=0}^{i} a_j (4)\n",
    "$$\n",
    "\n",
    "Now, the $a_j$ represent the rate of change of the variable $b_i$. Next, we replace the [4] in [3]\n",
    "$$\n",
    "odd_i = \\prod_{j=0}^{i-1} a_j * odd_{i-1}\n",
    "$$\n",
    "$$\n",
    "odd_i = \\prod_{j=0}^{i-1} a_j * \\prod_{j=0}^{i-2} a_j * odd_{i-2}\n",
    "$$\n",
    "$$\n",
    "odd_i = \\prod_{k=0}^{i-1}\\prod_{j=0}^{k} a_j * odd_{0}\n",
    "$$\n",
    "$$\n",
    "odd_i = \\prod_{j=0}^{i-1} a_j^{i-j} * odd_{0}\n",
    "$$\n",
    "\n",
    "Now, we liniarize this result and we generalize it to the case where $i=0$ using the $max$ function:\n",
    "\n",
    "$$\n",
    "log(odd_i) = \\sum_{j=0}^{max(i-1, 0)} (i-j)log(a_j)  +  log(odd_{0}) (5)\n",
    "$$\n",
    "\n",
    "We can write [5] as a linear problem with the following definitions:\n",
    "\n",
    "$$\n",
    "y = X \\beta + \\beta_0\n",
    "$$\n",
    "\n",
    "$$\n",
    "y_i = log(odd_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "X_{i,j} =  max(i-j, 0)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta_i =  log(a_i) (6)\n",
    "$$\n",
    "\n",
    "Now if we apply a LASSO regression we will find the solution that minimize the following cost function\n",
    "\n",
    "$$\n",
    "Err = \\sum (y-\\hat{y})^2 + \\alpha |\\beta|_1\n",
    "$$\n",
    "\n",
    "Hopefully, this solution will be sparse which means that most of the $\\beta_i$ will be $0$, and hence $a_i=1$.\n",
    "This is equivalent to say that the $b_i$ are almost constant except at the values whete $a_i \\neq 1$.\n",
    "\n",
    "\n",
    "\n",
    "[1] Bettencourt, L. M. A., & Ribeiro, R. M. (2008). Real time bayesian estimation of the epidemic potential of emerging infectious diseases. PLoS ONE, 3(5). https://doi.org/10.1371/journal.pone.0002185\n",
    "\n",
    "[2] Sanche, S., Lin, Y. T., Xu, C., Romero-Severson, E., Hengartner, N., & Ke, R. (2020). High Contagiousness and Rapid Spread of Severe Acute Respiratory Syndrome Coronavirus 2. Emerging Infectious Diseases, 26(7). https://doi.org/10.3201/eid2607.200282\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "\n",
    "This cell contains the main class: LassoICSelector. Its main method is fit_best_alpha. It works as follows:\n",
    "```\n",
    "For each alpha value:\n",
    "    1. Fits a lasso regression to the data\n",
    "    2. Selectes the first non zero variable from each chunck\n",
    "    3. Fits a linear regression with the selected variables\n",
    "    4. Excludes all non sifgificative (p-value>0.05) variables and fits a linear model again\n",
    "\n",
    "The linear model with less AIC from step 4 is selected.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstInChunkSelector(object):\n",
    "    '''Selects first element from each non zero chunk.'''\n",
    "\n",
    "    def __init__(self, clf):\n",
    "        self.clf = clf\n",
    "        self.coef = None\n",
    "        self.mask = None\n",
    "\n",
    "    def select_coef(self):\n",
    "        n_features = len(self.clf.coef_)\n",
    "        no_zero = np.zeros(n_features+1)\n",
    "        no_zero[1:] = self.clf.coef_ != 0\n",
    "        self.mask = np.diff(no_zero)>0\n",
    "        self.mask[0] = True\n",
    "        self.coef = self.clf.coef_[self.mask]\n",
    "        return self.coef\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.select_coef()\n",
    "        return X[:, self.mask]\n",
    "\n",
    "    def get_support(self):\n",
    "        self.select_coef()\n",
    "        return self.mask\n",
    "\n",
    "    def get_number_of_features(self):\n",
    "        self.select_coef()\n",
    "        return sum(self.mask)\n",
    "\n",
    "\n",
    "class LassoICSelector(object):\n",
    "    \"\"\"LASSO regression with FirstInChunk selector.\"\"\"\n",
    "\n",
    "    def __init__(self, X, y, criterion, alpha=0.05):\n",
    "        self.lasso = linear_model.LassoLars(alpha=0, max_iter=100000)\n",
    "        self.criterion = criterion\n",
    "        self.selector = FirstInChunkSelector(self.lasso)\n",
    "        self.OLS = sm.OLS\n",
    "        self.ols = self.OLS(y, X)\n",
    "        self.ols_results = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.final_ols = False\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def transform_to_ols(self, X):\n",
    "        '''Selects only the features of X are used by OLS.\n",
    "        Also, adds a coloumn with ones for the intercept.\n",
    "        '''\n",
    "\n",
    "        X_new = self.selector.transform(X)\n",
    "        if self.final_ols:\n",
    "            X_new = X[:, self.support]\n",
    "        X_new_with_cte = np.hstack([X_new, np.ones((X_new.shape[0], 1))])\n",
    "        return X_new_with_cte\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''Selects features and fits the OLS.'''\n",
    "\n",
    "        # select features\n",
    "        X_new = self.transform_to_ols(X)\n",
    "\n",
    "        # fit ols\n",
    "        self.ols = self.OLS(y, X_new)\n",
    "        self.ols_results = self.ols.fit()\n",
    "\n",
    "        # iteratively remove non signicative variables and fit again\n",
    "        mask = self.ols_results.pvalues < self.alpha / len(self.ols_results.pvalues)\n",
    "        mask[0] = True\n",
    "        Xnew = self.transform_to_ols(X)\n",
    "        Xnew = Xnew[:, mask]\n",
    "        self.support = self.selector.get_support()\n",
    "        self.ols = self.OLS(y, Xnew)\n",
    "        self.ols_results = self.ols.fit()\n",
    "        while any(self.ols_results.pvalues[1:] >= self.alpha / len(self.ols_results.pvalues)):\n",
    "            mask.values[mask.values] = (self.ols_results.pvalues < self.alpha / len(self.ols_results.pvalues)).values\n",
    "            mask[0] = True\n",
    "            Xnew = self.transform_to_ols(X)\n",
    "            Xnew = Xnew[:, mask]\n",
    "            self.support = self.selector.get_support()\n",
    "            self.ols = self.OLS(y, Xnew)\n",
    "            self.ols_results = self.ols.fit()\n",
    "\n",
    "        self.support[self.support] = mask[:-1]\n",
    "\n",
    "    def fit_best_alpha(self, X, y):\n",
    "        '''returns the model with the lowst cirterion.'''\n",
    "\n",
    "        self.lasso.fit(X, y)\n",
    "        alphas = self.lasso.alphas_\n",
    "        self.criterions_ = np.zeros(len(alphas))\n",
    "        self.log_liklehods = np.zeros(len(alphas))\n",
    "        \n",
    "        \n",
    "        for i, alpha in enumerate(alphas):\n",
    "            self.lasso.coef_ = self.lasso.coef_path_[:, i]\n",
    "            self.fit(X, y)\n",
    "            self.criterions_[i], self.log_liklehods[i] = self.get_criterion(self.ols.exog, y)\n",
    "        \n",
    "        # we use a list of tuples to find the minimum cirterion value.\n",
    "        # If there are ties, we use the maximum alpha value.\n",
    "        criterions_idx = list(zip(self.criterions_, alphas, range(len(alphas))))\n",
    "        criterion, alpha, idx = min(criterions_idx, key=lambda x: (x[0], -x[1]))\n",
    "        #print(list(enumerate(zip(alphas, self.criterions_))))\n",
    "        #print(alpha, criterion)\n",
    "        self.lasso.coef_ = self.lasso.coef_path_[:, idx]\n",
    "        self.lasso.alpha = alpha\n",
    "        self.fit(X, y)\n",
    "        self.final_ols = True\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''Predicts y useing the OLS fit.'''\n",
    "\n",
    "        return self.ols.predict(self.ols_results.params, X)\n",
    "\n",
    "    def log_liklihood(self, X, y):\n",
    "        '''Computes the log liklihood assuming normally distributed errors.'''\n",
    "\n",
    "        eps64 = np.finfo('float64').eps\n",
    "\n",
    "        # residuals\n",
    "        R = y - self.predict(X)\n",
    "        sigma2 = np.var(R)\n",
    "\n",
    "        loglike = -0.5 * len(R) * np.log(sigma2)\n",
    "        loglike -= 0.5 * len(R) * np.log(2*np.pi) - 0.5*len(R) + 0.5\n",
    "        return loglike\n",
    "\n",
    "    def get_criterion(self, X, y):\n",
    "        '''Computes AIC or BIC criterion.'''\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        if self.criterion == 'aic':\n",
    "            K = 2  # AIC\n",
    "        elif self.criterion == 'bic':\n",
    "            K = np.log(n_samples)\n",
    "        else:\n",
    "            raise ValueError('criterion should be either bic or aic')\n",
    "\n",
    "        log_like = self.log_liklihood(X, y)\n",
    "        df = X.shape[1]\n",
    "\n",
    "        aic = K * df - 2*log_like\n",
    "        self.criterion_ = aic\n",
    "\n",
    "        return self.criterion_, log_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit\n",
    "Now, we create the linear system and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "         State & $R^2$ &   N &  df_model &   fvalue & f_pvalue \\\\\n",
      "\\midrule\n",
      "      New York & 0.989 &  62 &         4 & 1251.214 & 8.60e-55 \\\\\n",
      " Massachusetts & 0.982 &  64 &         3 & 1062.281 & 6.21e-52 \\\\\n",
      "      Michigan & 0.971 &  62 &         3 &  639.142 & 2.23e-44 \\\\\n",
      "   Connecticut & 0.956 &  61 &         3 &  411.954 & 1.38e-38 \\\\\n",
      "  Rhode Island & 0.838 &  47 &         2 &  113.879 & 4.02e-18 \\\\\n",
      "      Virginia & 0.715 &  56 &         2 &   66.555 & 3.50e-15 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "lics_dict = {}\n",
    "#fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 8))\n",
    "gof_list = []\n",
    "for i, state in enumerate(df.State.unique()):\n",
    "    dfstate = df[df['State']==state]\n",
    "    # create the independent and the dependent variables\n",
    "    y = np.log(dfstate['Odds'])\n",
    "    X = np.tri(len(y))\n",
    "    X = np.cumsum(X, axis=0)[:, 1:]\n",
    "    X = X[dfstate.Odds.notna(), :]\n",
    "    y = y[dfstate.Odds.notna()]\n",
    "\n",
    "    # create lasso instance\n",
    "    lics = LassoICSelector(X, y.values, 'bic')\n",
    "\n",
    "    # fit\n",
    "    lics.fit_best_alpha(X, y)\n",
    "    lics_dict[state] = lics\n",
    "\n",
    "    #     ax = sns.lineplot(lics.lasso.alphas_, lics.criterions_, ax=axes[2, i])\n",
    "    #     ax.vlines(lics.lasso.alpha, min(lics.criterions_), max(lics.criterions_))\n",
    "    #     ax.set_ylabel('BIC')\n",
    "    #     ax.set_xlabel('Alpha')\n",
    "    #     ax.set_xscale('log')\n",
    "    #     axes[0, i].plot(lics.lasso.alphas_, lics.lasso.coef_path_.T)\n",
    "    #     axes[0, i].set_xscale('log')\n",
    "    #     axes[0, i].set_title(state)\n",
    "    #     axes[0, i].set_xlabel('Alpha')\n",
    "    #     axes[0, i].set_ylabel('Coefficient Value')\n",
    "    #     axes[0, i].vlines(lics.lasso.alpha, lics.lasso.coef_path_.min(), lics.lasso.coef_path_.max())\n",
    "    #     axes[1, i].plot(lics.lasso.coef_)\n",
    "    #     axes[1, i].scatter(np.arange(len(lics.lasso.coef_))[lics.support], lics.lasso.coef_[lics.support])\n",
    "    #     axes[1, i].set_xlabel('Coefficient #')\n",
    "    #     axes[1, i].set_ylabel('Coefficient Value')\n",
    "    #     print(state)\n",
    "    #     print('{} & {} & {} & {} & {} & {}'.format(state, lics.ols_results.rsquared, lics.ols_results.nobs, lics.ols_results.df_model, lics.ols_results.fvalue, lics.ols_results.f_pvalue))\n",
    "    #     display(lics.ols_results.summary())\n",
    "    gof_list.append({\"State\":state, '$R^2$':lics.ols_results.rsquared, \"N\": int(lics.ols_results.nobs), \"df_model\": int(lics.ols_results.df_model), \"fvalue\":lics.ols_results.fvalue, \"f_pvalue\":lics.ols_results.f_pvalue})\n",
    "# plt.tight_layout(pad=0.0)\n",
    "# plt.savefig('figs/framework.jpg', dpi=300)\n",
    "# plt.show()\n",
    "gof = pd.DataFrame(gof_list).sort_values('$R^2$', ascending=False)\n",
    "out = gof.to_latex(index=False,formatters={\"$R^2$\": \"{:0.3f}\".format, 'fvalue':\"{:0.3f}\".format, 'f_pvalue': \"{:.2e}\".format},\n",
    "             bold_rows=True, escape=False)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets copy the fitted values to a dataframe, and calculate the parameters and erros of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>R</th>\n",
       "      <th>R_l</th>\n",
       "      <th>R_u</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>2.097828</td>\n",
       "      <td>1.943739</td>\n",
       "      <td>2.251917</td>\n",
       "      <td>0.308179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>1.567515</td>\n",
       "      <td>1.431863</td>\n",
       "      <td>1.703166</td>\n",
       "      <td>0.271303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>0.726109</td>\n",
       "      <td>0.675574</td>\n",
       "      <td>0.776644</td>\n",
       "      <td>0.101070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>0.439509</td>\n",
       "      <td>0.415892</td>\n",
       "      <td>0.463126</td>\n",
       "      <td>0.047234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         R       R_l       R_u     delta\n",
       "0  2020-03-15  2.097828  1.943739  2.251917  0.308179\n",
       "8  2020-03-23  1.567515  1.431863  1.703166  0.271303\n",
       "15 2020-03-30  0.726109  0.675574  0.776644  0.101070\n",
       "30 2020-04-14  0.439509  0.415892  0.463126  0.047234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecticut\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>R</th>\n",
       "      <th>R_l</th>\n",
       "      <th>R_u</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>1.961695</td>\n",
       "      <td>1.782047</td>\n",
       "      <td>2.141343</td>\n",
       "      <td>0.359295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>0.974081</td>\n",
       "      <td>0.900267</td>\n",
       "      <td>1.047895</td>\n",
       "      <td>0.147629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>0.586444</td>\n",
       "      <td>0.557134</td>\n",
       "      <td>0.615755</td>\n",
       "      <td>0.058620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date         R       R_l       R_u     delta\n",
       "62 2020-03-20  1.961695  1.782047  2.141343  0.359295\n",
       "71 2020-03-29  0.974081  0.900267  1.047895  0.147629\n",
       "86 2020-04-13  0.586444  0.557134  0.615755  0.058620"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Massachusetts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>R</th>\n",
       "      <th>R_l</th>\n",
       "      <th>R_u</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>1.885402</td>\n",
       "      <td>1.827836</td>\n",
       "      <td>1.942968</td>\n",
       "      <td>0.115132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>1.120803</td>\n",
       "      <td>1.086757</td>\n",
       "      <td>1.154849</td>\n",
       "      <td>0.068092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>0.657329</td>\n",
       "      <td>0.641087</td>\n",
       "      <td>0.673571</td>\n",
       "      <td>0.032484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date         R       R_l       R_u     delta\n",
       "123 2020-03-15  1.885402  1.827836  1.942968  0.115132\n",
       "136 2020-03-28  1.120803  1.086757  1.154849  0.068092\n",
       "152 2020-04-13  0.657329  0.641087  0.673571  0.032484"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michigan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>R</th>\n",
       "      <th>R_l</th>\n",
       "      <th>R_u</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>1.464358</td>\n",
       "      <td>1.393495</td>\n",
       "      <td>1.535221</td>\n",
       "      <td>0.141726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>0.415219</td>\n",
       "      <td>0.368090</td>\n",
       "      <td>0.462348</td>\n",
       "      <td>0.094258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>0.670931</td>\n",
       "      <td>0.612907</td>\n",
       "      <td>0.728954</td>\n",
       "      <td>0.116047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date         R       R_l       R_u     delta\n",
       "187 2020-03-17  1.464358  1.393495  1.535221  0.141726\n",
       "205 2020-04-04  0.415219  0.368090  0.462348  0.094258\n",
       "227 2020-04-26  0.670931  0.612907  0.728954  0.116047"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rhode Island\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>R</th>\n",
       "      <th>R_l</th>\n",
       "      <th>R_u</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>1.070697</td>\n",
       "      <td>1.005958</td>\n",
       "      <td>1.135437</td>\n",
       "      <td>0.129479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>0.714994</td>\n",
       "      <td>0.672172</td>\n",
       "      <td>0.757816</td>\n",
       "      <td>0.085644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date         R       R_l       R_u     delta\n",
       "249 2020-04-01  1.070697  1.005958  1.135437  0.129479\n",
       "268 2020-04-20  0.714994  0.672172  0.757816  0.085644"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virginia\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>R</th>\n",
       "      <th>R_l</th>\n",
       "      <th>R_u</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>1.128474</td>\n",
       "      <td>1.105610</td>\n",
       "      <td>1.151338</td>\n",
       "      <td>0.045728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>0.903314</td>\n",
       "      <td>0.881409</td>\n",
       "      <td>0.925218</td>\n",
       "      <td>0.043809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date         R       R_l       R_u     delta\n",
       "296 2020-03-23  1.128474  1.105610  1.151338  0.045728\n",
       "323 2020-04-19  0.903314  0.881409  0.925218  0.043809"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_list = []\n",
    "Rt_dict = {}\n",
    "for state in df.State.unique():\n",
    "    print(state)\n",
    "    lics = lics_dict[state]\n",
    "    data = df[df['State']==state].copy()\n",
    "\n",
    "    # yhat = lics.ols_results.fittedvalues\n",
    "    y = np.log(data['Odds'])\n",
    "    X = np.tri(len(y))\n",
    "    X = np.cumsum(X, axis=0)[:, 1:]\n",
    "    Xols = lics.transform_to_ols(X)\n",
    "    yhat = lics.ols.predict(lics.ols_results.params, Xols)\n",
    "    # from equation 5\n",
    "    odds_hat = np.exp(yhat)\n",
    "\n",
    "    # the error in yhat is\n",
    "    # Xols = lics.transform_to_ols(X)\n",
    "    (yhat_std, yhat_l, yhat_u) = wls_prediction_std(lics.ols_results, Xols)\n",
    "    oddshat_l = np.exp(yhat-2*yhat_std)\n",
    "    oddshat_u = np.exp(yhat+2*yhat_std)\n",
    "\n",
    "    data.loc[:, 'odds_hat'] = odds_hat\n",
    "    data.loc[:, 'oddshat_l'] = oddshat_l\n",
    "    data.loc[:, 'oddshat_u'] = oddshat_u\n",
    "\n",
    "    # use coefficients to calculate Rt\n",
    "    coef = np.zeros(len(data))\n",
    "    coef_std = np.zeros_like(coef) * np.nan\n",
    "    ind = np.squeeze(np.argwhere(lics.support))\n",
    "\n",
    "    # we do not use the last coefficient since it's the intercept (=log(odds_0))\n",
    "    coef[ind] = lics.ols_results.params[:-1]\n",
    "\n",
    "    # using equation 2, 4 and 6\n",
    "    data.loc[:, 'R'] = np.cumsum(coef)/GAMMA+1\n",
    "\n",
    "    # get covarinace matrix of coefficients\n",
    "    cov = lics.ols_results.cov_params().values\n",
    "\n",
    "    # since the values of Rts are a sum of variables, we use the formula\n",
    "    # of the sum of gaussian variables with a known covariance matrix\n",
    "    stds = [np.sqrt(cov[:n, :n].sum()) for n in range(1, cov.shape[0])]\n",
    "    if len(stds)==1:\n",
    "        stds = stds[0]\n",
    "    coef_std[ind] = stds\n",
    "\n",
    "    # error propagation formula\n",
    "    data.loc[:, 'Rstd'] = coef_std / GAMMA\n",
    "\n",
    "    data['Rstd'] = data['Rstd'].fillna(method='ffill')\n",
    "    data['R_l'] = data['R'] - 2*data['Rstd']\n",
    "    data['R_u'] = data['R'] + 2*data['Rstd']\n",
    "\n",
    "    r_index = data.R.diff() != 0\n",
    "    Rts = data.loc[r_index, ['Date', 'R', 'R_l', 'R_u']]\n",
    "    Rts['delta'] = Rts['R_u'] - Rts['R_l']\n",
    "    Rt_dict[state] = Rts\n",
    "    display(Rts)\n",
    "    #print(np.cumsum(coef)[r_index], coef_std[r_index])\n",
    "    data_list.append(data)\n",
    "data = pd.concat(data_list)\n",
    "Rts = pd.concat(Rt_dict, names=['Dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Values of $R_t$ for each dataset and times of $R_t$ change.}\n",
      "\\label{tab:rt}\n",
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "       Dataset &       Date &      R &       95 \\% C.I. \\\\\n",
      "\\midrule\n",
      "      New York & 2020-03-15 &   2.10 &    (1.94, 2.25) \\\\\n",
      "      New York & 2020-03-23 &   1.57 &     (1.43, 1.7) \\\\\n",
      "      New York & 2020-03-30 &   0.73 &    (0.68, 0.78) \\\\\n",
      "      New York & 2020-04-14 &  0.440 &  (0.416, 0.463) \\\\\n",
      "   Connecticut & 2020-03-20 &   1.96 &    (1.78, 2.14) \\\\\n",
      "   Connecticut & 2020-03-29 &   0.97 &     (0.9, 1.05) \\\\\n",
      "   Connecticut & 2020-04-13 &  0.586 &  (0.557, 0.616) \\\\\n",
      " Massachusetts & 2020-03-15 &   1.89 &    (1.83, 1.94) \\\\\n",
      " Massachusetts & 2020-03-28 &  1.121 &  (1.087, 1.155) \\\\\n",
      " Massachusetts & 2020-04-13 &  0.657 &  (0.641, 0.674) \\\\\n",
      "      Michigan & 2020-03-17 &   1.46 &    (1.39, 1.54) \\\\\n",
      "      Michigan & 2020-04-04 &  0.415 &  (0.368, 0.462) \\\\\n",
      "      Michigan & 2020-04-26 &   0.67 &    (0.61, 0.73) \\\\\n",
      "  Rhode Island & 2020-04-01 &   1.07 &    (1.01, 1.14) \\\\\n",
      "  Rhode Island & 2020-04-20 &  0.715 &  (0.672, 0.758) \\\\\n",
      "      Virginia & 2020-03-23 &  1.128 &  (1.106, 1.151) \\\\\n",
      "      Virginia & 2020-04-19 &  0.903 &  (0.881, 0.925) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rts = pd.concat(Rt_dict, names=['Dataset'])\n",
    "Rts = Rts.reset_index().drop('level_1', axis=1)#[['Dataset', 'Date', 'R', #.rename(columns={'level_'})\n",
    "'('+Rts.R_l.round(2).astype(str)\n",
    "\n",
    "Rts['figures'] = (-np.floor(np.log10(Rts.delta))+1).astype(int)\n",
    "Rts['R'] = Rts.apply(lambda row: np.round(row['R'], row['figures']), axis=1)\n",
    "Rts['R'] = Rts.apply(lambda row: '{:0.{}f}'.format(row['R'], row['figures']), axis=1)\n",
    "Rts['R_l'] = Rts.apply(lambda row: np.round(row['R_l'], row['figures']), axis=1)\n",
    "Rts['R_u'] = Rts.apply(lambda row: np.round(row['R_u'], row['figures']), axis=1)\n",
    "Rts['95 % C.I.'] = Rts.apply(lambda row: '({}, {})'.format(row['R_l'], row['R_u']), axis=1)\n",
    "print(Rts[['Dataset', 'Date', 'R', '95 % C.I.']].to_latex(caption='Values of $R_t$ for each dataset and times of $R_t$ change.',\n",
    "                                                         label='tab:rt', index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Parameter values and statistics for the selected model for each dataset}\n",
      "\\label{tab:coef}\n",
      "\\begin{tabular}{llllr}\n",
      "\\toprule\n",
      "       Dataset & Coef. Name & Coefficient &           95\\% C.I. &  p-value \\\\\n",
      "\\midrule\n",
      "      New York &         x1 &     $0.146$ &    $(0.126, 0.167)$ & 1.94e-20 \\\\\n",
      "      New York &         x2 &    $-0.071$ &  $(-0.106, -0.036)$ & 1.60e-04 \\\\\n",
      "      New York &         x3 &    $-0.112$ &  $(-0.135, -0.089)$ & 7.51e-14 \\\\\n",
      "      New York &         x4 &    $-0.038$ &  $(-0.047, -0.029)$ & 8.96e-12 \\\\\n",
      "      New York &      const &     $-1.70$ &    $(-1.81, -1.59)$ & 4.50e-37 \\\\\n",
      "   Connecticut &         x1 &     $0.128$ &    $(0.104, 0.152)$ & 2.90e-15 \\\\\n",
      "   Connecticut &         x2 &    $-0.132$ &  $(-0.163, -0.101)$ & 9.93e-12 \\\\\n",
      "   Connecticut &         x3 &    $-0.052$ &  $(-0.064, -0.039)$ & 2.57e-11 \\\\\n",
      "   Connecticut &      const &     $-1.54$ &    $(-1.70, -1.39)$ & 6.68e-27 \\\\\n",
      " Massachusetts &         x1 &     $0.118$ &    $(0.110, 0.126)$ & 1.94e-38 \\\\\n",
      " Massachusetts &         x2 &    $-0.102$ &  $(-0.113, -0.091)$ & 2.48e-26 \\\\\n",
      " Massachusetts &         x3 &    $-0.062$ &  $(-0.068, -0.056)$ & 1.34e-28 \\\\\n",
      " Massachusetts &      const &     $-2.65$ &    $(-2.72, -2.58)$ & 5.14e-61 \\\\\n",
      "      Michigan &         x1 &     $0.062$ &    $(0.052, 0.071)$ & 5.51e-19 \\\\\n",
      "      Michigan &         x2 &    $-0.140$ &  $(-0.154, -0.126)$ & 2.03e-27 \\\\\n",
      "      Michigan &         x3 &     $0.034$ &    $(0.022, 0.047)$ & 1.22e-06 \\\\\n",
      "      Michigan &      const &     $-1.42$ &    $(-1.54, -1.30)$ & 1.67e-31 \\\\\n",
      "  Rhode Island &         x1 &     $0.009$ &    $(0.001, 0.018)$ & 3.43e-02 \\\\\n",
      "  Rhode Island &         x2 &    $-0.047$ &  $(-0.060, -0.035)$ & 3.29e-09 \\\\\n",
      "  Rhode Island &      const &     $-1.93$ &    $(-2.04, -1.81)$ & 9.00e-33 \\\\\n",
      "      Virginia &         x1 &    $0.0171$ &  $(0.0141, 0.0202)$ & 1.21e-15 \\\\\n",
      "      Virginia &         x2 &    $-0.030$ &  $(-0.035, -0.025)$ & 1.18e-15 \\\\\n",
      "      Virginia &      const &     $-2.22$ &    $(-2.27, -2.16)$ & 1.24e-56 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = 'New York'\n",
    "params_stats_list = []\n",
    "for state in lics_dict:\n",
    "    res = lics_dict[state].ols_results\n",
    "    dir(res)\n",
    "    params_stats = res.params\n",
    "    params_stats = pd.DataFrame({'Coef. Name': res.params.index,\n",
    "                                 'Coefficient':res.params, \n",
    "                                 'Std': pd.Series(np.diag(res.cov_params())**0.5, index=res.cov_params().index),\n",
    "                                  'p-value': res.pvalues},\n",
    "                                index=res.params.index)\n",
    "    params_stats['c_l'] = params_stats['Coefficient']-2*params_stats['Std']\n",
    "    params_stats['c_u'] = params_stats['Coefficient']+2*params_stats['Std']\n",
    "    params_stats['delta'] = 4*params_stats['Std']\n",
    "    params_stats['figures'] = (-np.floor(np.log10(params_stats.delta))+1).astype(int)\n",
    "    params_stats['c_u'] = params_stats.apply(lambda row: np.round(row['c_u'], row['figures']), axis=1)\n",
    "    params_stats['c_l'] = params_stats.apply(lambda row: np.round(row['c_l'], row['figures']), axis=1)\n",
    "    params_stats['Coefficient'] = params_stats.apply(lambda row: np.round(row['Coefficient'], row['figures']), axis=1)\n",
    "    params_stats['Coefficient'] = params_stats.apply(lambda row: '${:0.{}f}$'.format(row['Coefficient'], row['figures']), axis=1)\n",
    "    params_stats['c_u'] = params_stats.apply(lambda row: '{:0.{}f}'.format(row['c_u'], row['figures']), axis=1)\n",
    "    params_stats['c_l'] = params_stats.apply(lambda row: '{:0.{}f}'.format(row['c_l'], row['figures']), axis=1)\n",
    "    params_stats['95\\% C.I.'] = params_stats.apply(lambda row: '$({}, {})$'.format(row['c_l'], row['c_u']), axis=1)\n",
    "    params_stats['Dataset'] = state\n",
    "    params_stats_list.append(params_stats)\n",
    "\n",
    "params_stats = pd.concat(params_stats_list)[['Dataset', 'Coef. Name', 'Coefficient', '95\\% C.I.', 'p-value']]\n",
    "params_stats_latex = params_stats.to_latex(index=False,\n",
    "                                           label='tab:coef',\n",
    "                                           caption='Parameter values and statistics for the selected model for each dataset',\n",
    "                                           escape=False,\n",
    "                                           formatters={'p-value': \"{:.2e}\".format})\n",
    "print(params_stats_latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we plot the Rt as function of time and the fitted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741debb8bb4c48c3b29d5c08366d2222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84e90a81f5c401981e0e69d9dc5f2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "\n",
    "g1 = sns.FacetGrid(data.set_index('date'), col='State', col_wrap=2, ylim=[0, 2.5], aspect=1.5, dropna=False, col_order=gof.State)\n",
    "def myplot(data, y=None, color=None):\n",
    "    data.plot(x='Date', y=y, ax=plt.gca())\n",
    "#g1.map_dataframe(sns.lineplot, x='Date', y='R')\n",
    "g1.map_dataframe(myplot, y='R')\n",
    "g1.map(plt.fill_between, 'Date', 'R_u', 'R_l', alpha=0.2)\n",
    "#ax = data.plot(x='Date', y='R', legend=False)\n",
    "lines = []\n",
    "for ax, dsname in zip(g1.axes, gof.State):\n",
    "    if dsname in events:\n",
    "        for line in events[dsname]:\n",
    "            if line < pd.to_datetime('03-04-2020 00:00', dayfirst=True):\n",
    "                color = current_palette[1]\n",
    "                label = 'Mobility restrictions'\n",
    "            elif line == pd.to_datetime('03-04-2020 00:00', dayfirst=True):\n",
    "                color = 'k'\n",
    "                label = 'Masks (CDC)'\n",
    "            else:\n",
    "                label = 'Masks (State)'\n",
    "                color = current_palette[2]\n",
    "            lines.append(ax.axvline(line, 0,1, linestyle='--', color=color, label=label))\n",
    "\n",
    "#     lines_mr = [line for line in events[dsname] if line<pd.to_datetime('03-04-2020 00:00', dayfirst=True)]\n",
    "#     lines_masks = [line for line in events[dsname] if line>pd.to_datetime('03-04-2020 00:00', dayfirst=True)]\n",
    "#     ax.axvlines(lines_mr, 0,1, linestyle='--', color='r', label='Movility restrictions')\n",
    "#     ax.axvline(pd.to_datetime('03-04-2020 00:00', dayfirst=True), 0,1, linestyle='--', color='r', label='Masks (CDC)')\n",
    "#     ax.axvlines(lines_masks, 0,1, linestyle='--', color='r', label='Masks (Local)')\n",
    "\n",
    "g1.set(ylabel='$R_t$')\n",
    "#from pandas.plotting._matplotlib.timeseries import format_dateaxis\n",
    "#format_dateaxis(g1.axes[0,0], 1, data.index)\n",
    "#g1.axes[0,0].xaxis.set_major_locator(locator)\n",
    "#g1.axes[0,0].xaxis.set_major_formatter(formatter)\n",
    "g1.set(yscale='linear')\n",
    "g1.axes[0].legend([lines[0], lines[4], lines[5]], ['Mobility restrictions', 'Masks (CDC)', 'Masks (Local)'])\n",
    "#print(g1.axes[0, 0].legend().get_legend_handler_map())\n",
    "plt.xlabel('')\n",
    "\n",
    "g1.set(xlim=[data.date.min(), data.date.max()])\n",
    "g1.set_titles('{col_name}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/states6_RtL1.jpg', dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stacked = data.set_index(['Date', 'State'])[['Odds', 'odds_hat', 'oddshat_u', 'oddshat_l']]\n",
    "stacked = stacked.stack().reset_index().rename(columns={'level_2': 'variable', 0: 'val'})\n",
    "stacked['Branch'] = 'Fit'\n",
    "stacked.loc[stacked['variable'] == 'Odds', 'Branch'] = 'Data'\n",
    "stacked = stacked.set_index(['Date', 'State', 'Branch', 'variable']).unstack().reset_index()\n",
    "stacked.columns = ['Date', 'State', 'Branch', 'Odds', 'odds_hat', 'oddshat_u', 'oddshat_l']\n",
    "stacked = stacked.sort_values(['State', 'Date'])\n",
    "\n",
    "g = sns.FacetGrid(stacked, col='State', col_wrap=2, hue='Branch', aspect=1.3, dropna=False, hue_order=['Data', 'Fit'], col_order=gof.State)\n",
    "g.map_dataframe(sns.lineplot, x='Date', y='odds_hat')\n",
    "g.map_dataframe(sns.scatterplot, x='Date', y='Odds')\n",
    "g.map(plt.fill_between, 'Date', 'oddshat_l', 'oddshat_u', alpha=0.1)\n",
    "#.set_yscale('log')\n",
    "g.set(yscale='log')\n",
    "\n",
    "hl = g.axes[0].get_legend_handles_labels()\n",
    "\n",
    "handlers = [hl[0][1], hl[0][0]]\n",
    "labels = [hl[1][1], hl[1][0]]\n",
    "\n",
    "lh = {l:h for h,l in zip(handlers, labels)}\n",
    "# plt.ylabel('Odds')\n",
    "g.set(xlim = (data['Date'].min(), data['Date'].max()))\n",
    "g.set_titles('{col_name}')\n",
    "g.set(yscale='log')\n",
    "g.axes[0].xaxis.set_major_locator(locator)\n",
    "g.axes[0].xaxis.set_major_formatter(formatter)\n",
    "g.add_legend(lh, loc='lower center', bbox_to_anchor=(0.6, 0), title='', ncol=3)\n",
    "\n",
    "g.set(ylabel='Odds')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/states6_OddsL1.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71d57a9102d42859f7a824bacff5257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecticut\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a6b4d8106d4206968ad3263396df11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Massachusetts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b7747347604e45ab846930441a34e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michigan\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1581d740d8bb4e95a44a4af11b16f2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rhode Island\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b243594bf094e508e4aeb4eb24c45bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virginia\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a8c48bcc4e4ef99d1262270850a9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for state in df.State.unique():\n",
    "    print(state)\n",
    "    lics = lics_dict[state]\n",
    "    #data = df[df['State']==state].copy()\n",
    "\n",
    "    # yhat = lics.ols_results.fittedvalues\n",
    "    y = np.log(data.loc[data['State']==state, 'Odds'])\n",
    "    X = np.tri(len(y))\n",
    "    X = np.cumsum(X, axis=0)[:, 1:]\n",
    "    fitted_params = lics.ols_results.params.copy()\n",
    "    current_palette = sns.color_palette()\n",
    "\n",
    "\n",
    "    params_cf = lics.ols_results.params.copy()\n",
    "    params_cf[-2] = 0\n",
    "    lics.ols_results.params = params_cf\n",
    "    yhat = lics.predict(lics.transform_to_ols(X))\n",
    "    odds_cf = np.exp(yhat)\n",
    "    (yhat_std, yhat_l, yhat_u) = wls_prediction_std(lics.ols_results, lics.transform_to_ols(X))\n",
    "    oddshat_std = odds_cf*yhat_std\n",
    "\n",
    "    lics.ols_results.params = fitted_params\n",
    "    ratio_cf = odds_cf / (odds_cf+1)\n",
    "\n",
    "    coef = np.zeros(len(data.loc[data['State']==state]))\n",
    "    ind = np.squeeze(np.argwhere(lics.support))\n",
    "    coef[ind] = params_cf[:-1]\n",
    "    data.loc[data['State']==state, 'R_cf'] = np.cumsum(coef)/GAMMA+1\n",
    "\n",
    "    data.loc[data['State']==state, 'Odds CF'] = odds_cf\n",
    "    data.loc[data['State']==state, 'Odds CF std'] = oddshat_std\n",
    "    data.loc[data['State']==state, 'oddshat_l_cf'] = odds_cf - 2*oddshat_std\n",
    "    data.loc[data['State']==state, 'oddshat_u_cf'] = odds_cf + 2*oddshat_std\n",
    "\n",
    "    data.loc[data['State']==state, 'ratio_cf'] = ratio_cf\n",
    "    \n",
    "#     plt.figure()\n",
    "#     ax = sns.scatterplot(x='Date', y='Odds', data=data[data['State']==state], label='Data', c=np.array([current_palette[0]]))\n",
    "\n",
    "#     ax = sns.lineplot(x='Date', y='odds_hat', data=data[data['State']==state], ax=ax, palette=[current_palette[i]], label='Fit')\n",
    "#     ax.fill_between(data.loc[data['State']==state, 'Date'], data.loc[data['State']==state, 'oddshat_l'],\n",
    "#                     data.loc[data['State']==state, 'oddshat_u'],\n",
    "#                     alpha=0.1)\n",
    "\n",
    "#     ax = sns.lineplot(x='Date', y='Odds CF', data=data[data['State']==state], ax=ax, label='Counterfactual No Masks')#, palette=[current_palette[i]]\n",
    "#     ax.fill_between(data.loc[data['State']==state, 'Date'], data.loc[data['State']==state, 'oddshat_l_cf'],\n",
    "#                     data.loc[data['State']==state, 'oddshat_u_cf'],\n",
    "#                     alpha=0.1)\n",
    "\n",
    "#     plt.yscale('log')\n",
    "\n",
    "#     ax.xaxis.set_major_locator(locator)\n",
    "#     ax.xaxis.set_major_formatter(formatter)\n",
    "#     plt.grid(True)\n",
    "#     plt.ylabel('Odds')\n",
    "#     ax.set_xlim(data['Date'].min(), data.loc[data.odds_hat.notna(), 'Date'].max())\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig('figs/odds_cf_masks.jpg', dpi=300)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544588e9979b4fc7978bf7c28987f0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.close('all')\n",
    "# g1 = sns.FacetGrid(data, row='State', aspect=1.5)\n",
    "# g1.map_dataframe(sns.scatterplot, x='Date', y='Odds', label='Data')\n",
    "# g1.map_dataframe(sns.lineplot, x='Date', y='odds_hat', label='Fit')\n",
    "# def myfill_between(*args, **kwargs):\n",
    "#     ax = plt.gca()\n",
    "#     ax.fill_between(*args, **kwargs)\n",
    "# g1.map(myfill_between, 'Date', 'oddshat_l', 'oddshat_u', alpha=0.1)\n",
    "\n",
    "# g1.map_dataframe(sns.lineplot, x='Date', y='Odds CF', label='Counterfactual No Masks', palette=[current_palette[2]])\n",
    "# g1.map(plt.fill_between, 'Date', 'oddshat_l_cf', 'oddshat_u_cf', alpha=0.1)\n",
    "\n",
    "# plt.yscale('log')\n",
    "\n",
    "# #ax.xaxis.set_major_locator(locator)\n",
    "# #ax.xaxis.set_major_formatter(formatter)\n",
    "# #plt.grid(True)\n",
    "# #plt.ylabel('Odds')\n",
    "# g1.set(xlim=[data['Date'].min(), data.loc[data.odds_hat.notna(), 'Date'].max()])\n",
    "# #plt.tight_layout()\n",
    "# #plt.savefig('figs/odds_cf_masks.jpg', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed2cad94d3b4513b3acd6137da1ea1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fit': <matplotlib.lines.Line2D object at 0x7f99d2e40978>, 'Counterfactual': <matplotlib.lines.Line2D object at 0x7f99d2d91b38>, 'Data': <matplotlib.collections.PathCollection object at 0x7f99d2cc16a0>}\n"
     ]
    }
   ],
   "source": [
    "pepe = data.set_index(['Date', 'State', ])[['Odds', 'odds_hat', 'oddshat_u', 'oddshat_l', 'Odds CF', 'oddshat_u_cf', 'oddshat_l_cf']]\n",
    "pepe = pepe.stack().reset_index().rename(columns={'level_2': 'variable', 0: 'val'})\n",
    "pepe['Branch'] = 'Fit'\n",
    "pepe.loc[pepe['variable'].str.lower().str.contains('cf'), 'Branch'] = 'Counterfactual'\n",
    "pepe.loc[pepe['variable'] == 'Odds', 'Branch'] = 'Data'\n",
    "pepe.loc[pepe['variable']=='Odds CF', 'variable'] = 'odds_hat'\n",
    "pepe.loc[pepe['variable']=='oddshat_u_cf', 'variable'] = 'oddshat_u'\n",
    "pepe.loc[pepe['variable']=='oddshat_l_cf', 'variable'] = 'oddshat_l'\n",
    "pepe = pepe.set_index(['Date', 'State', 'Branch', 'variable']).unstack().reset_index()\n",
    "pepe.columns = ['Date', 'State', 'Branch', 'Odds', 'odds_hat', 'oddshat_u', 'oddshat_l']\n",
    "\n",
    "pepe = pepe[pepe['State'].isin(['New York', 'Connecticut', 'Massachusetts'])]\n",
    "plt.close('all')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "g1 = sns.FacetGrid(pepe, row='State', hue='Branch', aspect=1.5, dropna=False, hue_order=['Data', 'Fit', 'Counterfactual'])\n",
    "legend_and_hand = []\n",
    "def myplot(data, x=None, y=None, color=None, label=None):\n",
    "    ax = plt.gca()\n",
    "    ax = data.plot(x=x, y=y, ax=ax, label=label)\n",
    "    legend_and_hand.append(ax.get_legend_handles_labels())\n",
    "    return ax\n",
    "g1.map_dataframe(myplot, x='Date', y='odds_hat')\n",
    "g1.map_dataframe(sns.scatterplot, x='Date', y='Odds')\n",
    "\n",
    "\n",
    "g1.map(plt.fill_between, 'Date', 'oddshat_l', 'oddshat_u', alpha=0.1)\n",
    "hl = g1.axes[0,0].get_legend_handles_labels()\n",
    "\n",
    "lh = {l:h for h,l in zip(hl[0][1:4], hl[1][1:4])}\n",
    "print(lh)\n",
    "g1.add_legend(lh, loc='lower center', bbox_to_anchor=(0.7, 0), title='', ncol=3)#\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('')\n",
    "\n",
    "g1.set(xlim=[data['Date'].min(), data.loc[data.odds_hat.notna(), 'Date'].max()], ylabel='Odds')\n",
    "g1.set_titles(\"{row_name}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/odds_cf_masks.jpg', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York & Counterfactual cases diff 70948.16745793185 & CI (63796.08804496976 78100.24687089394)\n",
      "Connecticut & Counterfactual cases diff 28752.040635446097 & CI (26783.399365885663 30720.68190500653)\n",
      "Massachusetts & Counterfactual cases diff 68518.08656454261 & CI (66223.23845338057 70812.93467570464)\n",
      "All & Counterfactual cases diff 170744.7447070785 &  CI (162662.19649371173 178827.29292044527)\n",
      "Counterfactual death diff 13147.345342445044 CI (12524.989130015803 13769.701554874286)\n"
     ]
    }
   ],
   "source": [
    "for state in  ['New York', 'Connecticut', 'Massachusetts']:\n",
    "    subdata = data[data['State']==state]\n",
    "    Positives_CF = subdata['Tests'] * subdata['Odds CF']/(subdata['Odds CF']+1)\n",
    "    Positives_CF_std = subdata['Odds CF std'] * subdata['Tests'] /(subdata['Odds CF']+1)**2\n",
    "    Positives_CF_sum_std = np.sqrt((Positives_CF_std**2).sum())\n",
    "    Positive_diff = (Positives_CF - subdata['Positives']).sum()\n",
    "    Positive_diff_l = Positive_diff - 2* Positives_CF_sum_std\n",
    "    Positive_diff_u = Positive_diff + 2* Positives_CF_sum_std\n",
    "    Positives_fit = subdata['Tests'] * subdata['odds_hat']/(subdata['odds_hat']+1)\n",
    "    print('{} & Counterfactual cases diff {} & CI ({} {})'.format(state, Positive_diff, Positive_diff_l, Positive_diff_u))\n",
    "    #print('{} & Counterfactual death diff {} CI ({} {})'.format(0.077*Positive_diff, 0.077*Positive_diff_l, 0.077*Positive_diff_u))\n",
    "\n",
    "Positives_CF = data['Tests'] * data['Odds CF']/(data['Odds CF']+1)\n",
    "Positives_CF_std = data['Odds CF std'] * data['Tests'] /(data['Odds CF']+1)**2\n",
    "Positives_CF_sum_std = np.sqrt((Positives_CF_std**2).sum())\n",
    "Positive_diff = (Positives_CF - data['Positives']).sum()\n",
    "Positive_diff_l = Positive_diff - 2* Positives_CF_sum_std\n",
    "Positive_diff_u = Positive_diff + 2* Positives_CF_sum_std\n",
    "Positives_fit = data['Tests'] * data['odds_hat']/(data['odds_hat']+1)\n",
    "print('All & Counterfactual cases diff {} &  CI ({} {})'.format(Positive_diff, Positive_diff_l, Positive_diff_u))\n",
    "print('Counterfactual death diff {} CI ({} {})'.format(0.077*Positive_diff, 0.077*Positive_diff_l, 0.077*Positive_diff_u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York & Counterfactual cases diff 69994.19624824733 & CI (64432.791677056935 75555.60081943774)\n",
      "Connecticut & Counterfactual cases diff 23738.693581515065 & CI (22040.362151084515 25437.025011945614)\n",
      "Massachusetts & Counterfactual cases diff 65005.16464721143 & CI (62843.74865378189 67166.58064064097)\n",
      "All & Counterfactual cases diff 160720.81448234845 &  CI (154311.67138298787 167129.95758170902)\n",
      "Counterfactual death diff 12375.50271514083 CI (11881.998696490065 12869.006733791595)\n",
      "Analyzed span: 31 days 00:00:00\n"
     ]
    }
   ],
   "source": [
    "max_date = min(data.loc[data['State']=='New York', 'Date'].max(), data.loc[data['State']=='Connecticut', 'Date'].max(), data.loc[data['State']=='Massachusetts', 'Date'].max())\n",
    "min_date = pd.to_datetime('2020-04-14')\n",
    "for state in  ['New York', 'Connecticut', 'Massachusetts']:\n",
    "    subdata = data.loc[(data['State']==state) & (data['Date']<=max_date) & (data['Date']>=min_date)]\n",
    "    Positives_CF = subdata['Tests'] * subdata['Odds CF']/(subdata['Odds CF']+1)\n",
    "    Positives_CF_std = subdata['Odds CF std'] * subdata['Tests'] /(subdata['Odds CF']+1)**2\n",
    "    Positives_CF_sum_std = np.sqrt((Positives_CF_std**2).sum())\n",
    "    Positive_diff = (Positives_CF - subdata['Positives']).sum()\n",
    "    Positive_diff_l = Positive_diff - 2* Positives_CF_sum_std\n",
    "    Positive_diff_u = Positive_diff + 2* Positives_CF_sum_std\n",
    "    Positives_fit = subdata['Tests'] * subdata['odds_hat']/(subdata['odds_hat']+1)\n",
    "    print('{} & Counterfactual cases diff {} & CI ({} {})'.format(state, Positive_diff, Positive_diff_l, Positive_diff_u))\n",
    "\n",
    "ind = (data['Date']<=max_date) & (data['Date']>=min_date)\n",
    "Positives_CF = data.loc[ind, 'Tests'] * data.loc[ind, 'Odds CF']/(data.loc[ind, 'Odds CF']+1)\n",
    "Positives_CF_std = data.loc[ind, 'Odds CF std'] * data.loc[ind, 'Tests'] /(data.loc[ind, 'Odds CF']+1)**2\n",
    "Positives_CF_sum_std = np.sqrt((Positives_CF_std**2).sum())\n",
    "Positive_diff = (Positives_CF - data.loc[ind, 'Positives']).sum()\n",
    "Positive_diff_l = Positive_diff - 2* Positives_CF_sum_std\n",
    "Positive_diff_u = Positive_diff + 2* Positives_CF_sum_std\n",
    "Positives_fit = data.loc[ind, 'Tests'] * data.loc[ind, 'odds_hat']/(data.loc[ind, 'odds_hat']+1)\n",
    "print('All & Counterfactual cases diff {} &  CI ({} {})'.format(Positive_diff, Positive_diff_l, Positive_diff_u))\n",
    "print('Counterfactual death diff {} CI ({} {})'.format(0.077*Positive_diff, 0.077*Positive_diff_l, 0.077*Positive_diff_u))\n",
    "print('Analyzed span: {}'.format(max_date-min_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2020-05-15 00:00:00'), Timestamp('2020-05-19 00:00:00'), Timestamp('2020-05-17 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "max_dates = [data.loc[data['State']=='New York', 'Date'].max(), data.loc[data['State']=='Connecticut', 'Date'].max(), data.loc[data['State']=='Massachusetts', 'Date'].max()]\n",
    "print(max_dates)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
