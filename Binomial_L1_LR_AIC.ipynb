{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO Regresion on covid-19 cases in NYS\n",
    "\n",
    "## Load modulues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from sklearn import linear_model\n",
    "from scipy import stats as sps\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from IPython.display import display\n",
    "\n",
    "locator = mdates.AutoDateLocator()\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "GAMMA = 1/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interventin dates\n",
    "# 03/10/2020 school close in New Rochelle\n",
    "# https://www.governor.ny.gov/news/during-novel-coronavirus-briefing-governor-cuomo-announces-new-mass-gatherings-regulations\n",
    "# 03/12/2020 mass gathering reduced to 500 max. 50% occupancy\n",
    "\n",
    "\n",
    "# 03/17/2020 close of gyms, restaurants and bars, movie theaters, mass gathering up to 50. https://www.governor.ny.gov/news/amid-lack-federal-direction-governor-cuomo-governor-murphy-and-governor-lamont-announce\n",
    "bars = pd.to_datetime('03-16-2020 20:00', dayfirst=False)\n",
    "# 03/18/2020 school clousure http://www.nysed.gov/news/2020/state-education-department-issues-updated-guidance-schools-regarding-novel-coronavirus\n",
    "schools = pd.to_datetime('03-18-2020 20:00', dayfirst=False)\n",
    "\n",
    "# https://www.governor.ny.gov/news/amid-ongoing-covid-19-pandemic-governor-cuomo-announces-deployment-1000-bed-hospital-ship-usns\n",
    "# 03/20/2020 00:00 50% of the workforce\n",
    "workforce_50 = pd.to_datetime('03-20-2020 20:00', dayfirst=False)\n",
    "# 03/22/2020 20:00 ny_pause \n",
    "ny_pause = pd.to_datetime('22-03-2020 00:00', dayfirst=True)\n",
    "# CDC masks https://www.npr.org/sections/goatsandsoda/2020/04/10/829890635/why-there-so-many-different-guidelines-for-face-masks-for-the-public\n",
    "masks_cdc = pd.to_datetime('03-04-2020 00:00', dayfirst=True)\n",
    "mask_employers = pd.to_datetime('12-04-2020 00:00', dayfirst=True)\n",
    "mask_public = pd.to_datetime('17-04-2020 00:00', dayfirst=True)\n",
    "\n",
    "events = [bars, schools, workforce_50, ny_pause, masks_cdc, mask_employers, mask_public]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positives</th>\n",
       "      <th>Tests</th>\n",
       "      <th>Odds</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-15</th>\n",
       "      <td>294</td>\n",
       "      <td>1936</td>\n",
       "      <td>0.179050</td>\n",
       "      <td>2020-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-16</th>\n",
       "      <td>432</td>\n",
       "      <td>2907</td>\n",
       "      <td>0.174545</td>\n",
       "      <td>2020-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-17</th>\n",
       "      <td>1009</td>\n",
       "      <td>4553</td>\n",
       "      <td>0.284707</td>\n",
       "      <td>2020-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-18</th>\n",
       "      <td>1769</td>\n",
       "      <td>7698</td>\n",
       "      <td>0.298364</td>\n",
       "      <td>2020-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-19</th>\n",
       "      <td>2950</td>\n",
       "      <td>10124</td>\n",
       "      <td>0.411207</td>\n",
       "      <td>2020-03-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Positives  Tests      Odds       Date\n",
       "date                                             \n",
       "2020-03-15        294   1936  0.179050 2020-03-15\n",
       "2020-03-16        432   2907  0.174545 2020-03-16\n",
       "2020-03-17       1009   4553  0.284707 2020-03-17\n",
       "2020-03-18       1769   7698  0.298364 2020-03-18\n",
       "2020-03-19       2950  10124  0.411207 2020-03-19"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://health.data.ny.gov/resource/xdss-u53e.csv/?$limit=5000', usecols=['test_date', 'total_number_of_tests', 'new_positives'])\n",
    "df = df.rename(columns={'new_positives': 'Positives', 'total_number_of_tests': 'Tests', 'test_date': 'date'})\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.groupby('date').sum()\n",
    "\n",
    "df['Odds'] = df.Positives / (df.Tests - df.Positives)\n",
    "df['Date'] = pd.to_datetime(df.index)\n",
    "df = df[df['Date'] >= '2020-03-15']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "I we plot the number of positive tests we can see that the data is noisy.\n",
    "But, if we take into account the number of people tested each day, the data looks way more clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b55b2f214d430bb1cfdf5a21231fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca12ce97e99478aaf6dcd6142d5c2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "ax = df.plot(y=['Positives', 'Tests'], secondary_y=['Tests'], legend=True)\n",
    "plt.vlines(events, 0, df.Tests.max(), linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/tests_and_cases.jpg', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.scatterplot(data=df, x='Date', y='Odds')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim([df.Date.min(), df.Date.max()])\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_major_formatter(formatter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between the total number of infected individuals and positive tests\n",
    "\n",
    "As has been shown previously [[1]](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0002185), the number of new infected individuals in a given day $k_t$ is given by:\n",
    "$$\n",
    "k_t = k_{t-1} e^{(R_{t-1}-1)\\gamma}\n",
    "$$\n",
    "\n",
    "where $R_t$ is the effective reproductuve number and $\\gamma^{-1}$ is the infectious period estimated as 7 days accoring to [2].\n",
    "\n",
    "The following derivation was suggested to my by Will Meierjurgen Farr on this GitHub [Issue](https://github.com/k-sys/covid-19/issues/45#issuecomment-623782130). \n",
    "Since we do not have access to the total number of infected indiviudals, but only to the population being tested, we have to use some statisticals assumtions on this populations.\n",
    "If we asume that the people being tested, in a given day, is a sample of the population with COVID-19-like sympoms we can state that:\n",
    "\n",
    "$$\n",
    "n_{t} = [P_t(CV|sympoms) P_t(sympoms) +P_t(not CV|sympoms)P_t(sympoms)]Nf_t \n",
    "$$\n",
    "\n",
    "where $n_{t}$ is the number of people tested, $P_t(CV|sympoms)$ is the probablity of a pacient being positive for coronavirus given that the she is sympomatic, $P_t(sympoms)$ is the probablity of having COVID-like sympoms, $P_t(not CV|sympoms)$ is the probability of a pacient being coronavirus negative given he has COVID-19-like sympoms, $N$ is the total population, and $f_t$ is the fraction of people with sympoms that is selected to be tested (this number can be different each day, for example if the number of tests availabes changes).\n",
    "Also, note that the probability of a test being positive in a given day is $Positive_t=P_t(CV|sympoms) P_t(sympoms) N f_t$\n",
    "\n",
    "\n",
    "Now, if we assume that $P_t(sympoms|CV)=cte$ we can use Bayes theorem to show that:\n",
    "\n",
    "$$\n",
    "P_t(CV|sympoms) P_t(sympoms) \\propto P_t(CV) = \\frac{k_t}{N}\n",
    "$$\n",
    "\n",
    "Then:\n",
    "$$\n",
    "P_t(CV|sympoms) P_t(sympoms) \\propto k_t\n",
    "$$\n",
    "\n",
    "Finally, if we assume that $P_t(not CV|sympoms)P_t(sympoms)=cte$:\n",
    "$$\n",
    "Odds_t = \\frac{P(CV|sympoms) P(sympoms)Nf_t}{P_t(not CV|sympoms)P_t(sympoms)Nf_t} \\\\\n",
    "Odds_t = \\frac{P(CV|sympoms) P(sympoms)}{P_t(not CV|sympoms)P_t(sympoms)} \\\\\n",
    "Odds_t \\propto k_t \\\\\n",
    "$$\n",
    "\n",
    "\\begin{align}\n",
    "Odds_t = Odds_{t-1} e^{(R_{t-1}-1)\\gamma}\n",
    "\\label{eq:odds_rt}\\tag{1}\n",
    "\\end{align}\n",
    "\n",
    "We used three hypothesis. First, constant population $N$ (for $P_t \\propto k_t$ and for the evolution of $k_t$). Second, that the tested population is a random sample from the population with COVID19-like sympoms ($n_t = [P_t(CV|sympoms) P_t(sympoms) +P_t(not CV|sympoms)P_t(sympoms)]Nf_t$) this is not the case when people is being tested based on contacts for example. And third, that $P_t(not CV|sympoms)P_t(sympoms)=cte$, this is equivalent to say that the number of people with covid-19-like sympoms but without the coronavirus (for example people with the flu) is constant, or at least it changes are negligible compared with the changes in the amount of sympomatic people with coronavirus.\n",
    "\n",
    "## Linearization\n",
    "\n",
    "Defining\n",
    "\n",
    "$$\n",
    "b_i =  e^{(R_{i-1}-1)\\gamma}\n",
    "\\label{eq:bi_rt} \\tag{2}\n",
    "$$\n",
    "\n",
    "We can write \\ref{eq:odds_rt} as:\n",
    "\n",
    "\\begin{equation}\n",
    "odd_i = b_{i-1} * odd_{i-1}\n",
    "\\label{eq:odds1} \\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "Now, instead of using $b_i$ as the parameters to estimate we decompose each $b$ as follows:\n",
    "\n",
    "$$\n",
    "b_i = \\prod_{j=0}^{i} a_j\n",
    "\\label{eq:biai} \\tag{4}\n",
    "$$\n",
    "\n",
    "Now, the $a_j$ represent the rate of change of the variable $b_i$. Next, we replace the \\ref{eq:biai} in \\ref{eq:odds1}\n",
    "$$\n",
    "odd_i = \\prod_{j=0}^{i-1} a_j * odd_{i-1}\\\\\n",
    "odd_i = \\prod_{j=0}^{i-1} a_j * \\prod_{j=0}^{i-2} a_j * odd_{i-2}\\\\\n",
    "odd_i = \\prod_{k=0}^{i-1}\\prod_{j=0}^{k} a_j * odd_{0}\\\\\n",
    "odd_i = \\prod_{j=0}^{i-1} a_j^{i-j} * odd_{0}\\\\\n",
    "$$\n",
    "\n",
    "Now, we liniarize this result and we generalize it to the case where $i=0$ using the $max$ function:\n",
    "\n",
    "$$\n",
    "log(odd_i) = \\sum_{j=0}^{max(i-1, 0)} (i-j)log(a_j)  +  log(odd_{0})\n",
    "\\label{eq:logodds}\\tag{5}\n",
    "$$\n",
    "\n",
    "We can write \\ref{eq:logodds} as a linear problem with the following definitions:\n",
    "\n",
    "$$\n",
    "y = X \\beta + \\beta_0\n",
    "$$\n",
    "\n",
    "$$\n",
    "y_i = log(odd_i) \\\\\n",
    "X_{i,i} = \n",
    "\\begin{cases}\n",
    "i-j & i \\ge j \\\\\n",
    "0   & i < j\\\\\n",
    "\\end{cases}\\\\\n",
    "\\beta_i =  log(a_i)\n",
    "\\label{eq:linear_system}\\tag{6}\n",
    "$$\n",
    "\n",
    "Now if we apply a LASSO regression we will find the solution that minimize the following cost function\n",
    "\n",
    "$$\n",
    "Err = \\sum (y-\\hat{y})^2 + \\alpha |\\beta|_1\n",
    "$$\n",
    "\n",
    "Hopefully, this solution will be sparse which means that most of the $\\beta_i$ will be $0$, and hence $a_i=1$.\n",
    "This is equivalent to say that the $b_i$ are almost constant except at the values whete $a_i \\neq 1$.\n",
    "\n",
    "\n",
    "\n",
    "[1] Bettencourt, L. M. A., & Ribeiro, R. M. (2008). Real time bayesian estimation of the epidemic potential of emerging infectious diseases. PLoS ONE, 3(5). https://doi.org/10.1371/journal.pone.0002185\n",
    "\n",
    "[2] Sanche, S., Lin, Y. T., Xu, C., Romero-Severson, E., Hengartner, N., & Ke, R. (2020). High Contagiousness and Rapid Spread of Severe Acute Respiratory Syndrome Coronavirus 2. Emerging Infectious Diseases, 26(7). https://doi.org/10.3201/eid2607.200282\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "\n",
    "This cell contains the main class: LassoICSelector. Its main method is fit_best_alpha. It works as follows:\n",
    "```\n",
    "For each alpha value:\n",
    "    1. Fits a lasso regression to the data\n",
    "    2. Selectes the first non zero variable from each chunck\n",
    "    3. Fits a linear regression with the selected variables\n",
    "    4. Excludes all non sifgificative (p-value>0.05) variables and fits a linear model again\n",
    "\n",
    "The linear model with less AIC from step 4 is selected.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstInChunkSelector(object):\n",
    "    '''Selects first element from each non zero chunk.'''\n",
    "\n",
    "    def __init__(self, clf):\n",
    "        self.clf = clf\n",
    "        self.coef = None\n",
    "        self.mask = None\n",
    "\n",
    "    def select_coef(self):\n",
    "        n_features = len(self.clf.coef_)\n",
    "        no_zero = np.zeros(n_features+1)\n",
    "        no_zero[1:] = self.clf.coef_ != 0\n",
    "        self.mask = np.diff(no_zero)>0\n",
    "        self.coef = self.clf.coef_[self.mask]\n",
    "        return self.coef\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.select_coef()\n",
    "        return X[:, self.mask]\n",
    "\n",
    "    def get_support(self):\n",
    "        self.select_coef()\n",
    "        return self.mask\n",
    "\n",
    "    def get_number_of_features(self):\n",
    "        self.select_coef()\n",
    "        return sum(self.mask)\n",
    "\n",
    "\n",
    "class LassoICSelector(object):\n",
    "    \"\"\"LASSO regression with FirstInChunk selector.\"\"\"\n",
    "\n",
    "    def __init__(self, X, y, criterion):\n",
    "        self.lasso = linear_model.LassoLars(alpha=0, max_iter=100000)\n",
    "        self.criterion = criterion\n",
    "        self.selector = FirstInChunkSelector(self.lasso)\n",
    "        self.OLS = sm.OLS\n",
    "        self.ols = self.OLS(y, X)\n",
    "        self.ols_results = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.final_ols = False\n",
    "\n",
    "    def transform_to_ols(self, X):\n",
    "        '''Selects only the features of X are used by OLS.\n",
    "        Also, adds a coloumn with ones for the intercept.\n",
    "        '''\n",
    "\n",
    "        X_new = self.selector.transform(X)\n",
    "        if self.final_ols:\n",
    "            X_new = X[:, self.support]\n",
    "        X_new_with_cte = np.hstack([X_new, np.ones((X_new.shape[0], 1))])\n",
    "        return X_new_with_cte\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''Selects features and fits the OLS.'''\n",
    "\n",
    "        # select features\n",
    "        X_new = self.transform_to_ols(X)\n",
    "\n",
    "        # fit ols\n",
    "        self.ols = self.OLS(y, X_new)\n",
    "        self.ols_results = self.ols.fit()\n",
    "\n",
    "        # remove non signicative variables and fit again\n",
    "        mask = self.ols_results.pvalues < 0.05\n",
    "        Xnew = self.transform_to_ols(X)\n",
    "        Xnew = Xnew[:, mask]\n",
    "        self.support = self.selector.get_support()\n",
    "        self.ols = self.OLS(y, Xnew)\n",
    "        self.ols_results = self.ols.fit()\n",
    "\n",
    "        self.support[self.support] = mask[:-1]\n",
    "\n",
    "    def fit_best_alpha(self, X, y):\n",
    "        '''returns the model with the lowst cirterion.'''\n",
    "\n",
    "        self.lasso.fit(X, y)\n",
    "        alphas = self.lasso.alphas_\n",
    "        self.criterions_ = np.zeros(len(alphas))\n",
    "        self.log_liklehods = np.zeros(len(alphas))\n",
    "        \n",
    "        \n",
    "        for i, alpha in enumerate(alphas):\n",
    "            self.lasso.coef_ = self.lasso.coef_path_[:, i]\n",
    "            self.fit(X, y)\n",
    "            self.criterions_[i], self.log_liklehods[i] = self.get_criterion(self.ols.exog, y)\n",
    "        \n",
    "        # we use a list of tuples to find the minimum cirterion value.\n",
    "        # If there are ties, we use the maximum alpha value.\n",
    "        criterions_idx = list(zip(self.criterions_, alphas, range(len(alphas))))\n",
    "        criterion, alpha, idx = min(criterions_idx, key=lambda x: (x[0], -x[1]))\n",
    "        \n",
    "        self.lasso.coef_ = self.lasso.coef_path_[:, idx]\n",
    "        self.lasso.alpha = alpha\n",
    "        self.fit(X, y)\n",
    "        self.final_ols = True\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''Predicts y useing the OLS fit.'''\n",
    "\n",
    "        return self.ols.predict(self.ols_results.params, X)\n",
    "\n",
    "    def log_liklihood(self, X, y):\n",
    "        '''Computes the log liklihood assuming normally distributed errors.'''\n",
    "\n",
    "        eps64 = np.finfo('float64').eps\n",
    "\n",
    "        # residuals\n",
    "        R = y - self.predict(X)\n",
    "        sigma2 = np.var(R)\n",
    "\n",
    "        loglike = -0.5 * len(R) * np.log(sigma2)\n",
    "        loglike -= 0.5 * len(R) * np.log(2*np.pi) - 0.5*len(R) + 0.5\n",
    "        return loglike\n",
    "\n",
    "    def get_criterion(self, X, y):\n",
    "        '''Computes AIC or BIC criterion.'''\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        if self.criterion == 'aic':\n",
    "            K = 2  # AIC\n",
    "        elif self.criterion == 'bic':\n",
    "            K = np.log(n_samples)\n",
    "        else:\n",
    "            raise ValueError('criterion should be either bic or aic')\n",
    "\n",
    "        log_like = self.log_liklihood(X, y)\n",
    "        df = X.shape[1]\n",
    "\n",
    "        aic = K * df - 2*log_like\n",
    "        self.criterion_ = aic\n",
    "\n",
    "        return self.criterion_, log_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit\n",
    "Now, we create the linear system and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb994a44e2614afc85ba183103cc282e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Odds</td>       <th>  R-squared:         </th> <td>   0.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1721.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 21 May 2020</td> <th>  Prob (F-statistic):</th> <td>9.32e-63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:25:27</td>     <th>  Log-Likelihood:    </th> <td>  66.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    67</td>      <th>  AIC:               </th> <td>  -122.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    62</td>      <th>  BIC:               </th> <td>  -111.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.1462</td> <td>    0.010</td> <td>   14.228</td> <td> 0.000</td> <td>    0.126</td> <td>    0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0698</td> <td>    0.017</td> <td>   -3.991</td> <td> 0.000</td> <td>   -0.105</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1140</td> <td>    0.011</td> <td>  -10.027</td> <td> 0.000</td> <td>   -0.137</td> <td>   -0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0359</td> <td>    0.004</td> <td>   -8.618</td> <td> 0.000</td> <td>   -0.044</td> <td>   -0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -1.6965</td> <td>    0.055</td> <td>  -30.592</td> <td> 0.000</td> <td>   -1.807</td> <td>   -1.586</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.661</td> <th>  Durbin-Watson:     </th> <td>   2.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.059</td> <th>  Jarque-Bera (JB):  </th> <td>   6.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.321</td> <th>  Prob(JB):          </th> <td>  0.0405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.373</td> <th>  Cond. No.          </th> <td>    291.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   Odds   R-squared:                       0.991\n",
       "Model:                            OLS   Adj. R-squared:                  0.990\n",
       "Method:                 Least Squares   F-statistic:                     1721.\n",
       "Date:                Thu, 21 May 2020   Prob (F-statistic):           9.32e-63\n",
       "Time:                        13:25:27   Log-Likelihood:                 66.421\n",
       "No. Observations:                  67   AIC:                            -122.8\n",
       "Df Residuals:                      62   BIC:                            -111.8\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.1462      0.010     14.228      0.000       0.126       0.167\n",
       "x2            -0.0698      0.017     -3.991      0.000      -0.105      -0.035\n",
       "x3            -0.1140      0.011    -10.027      0.000      -0.137      -0.091\n",
       "x4            -0.0359      0.004     -8.618      0.000      -0.044      -0.028\n",
       "const         -1.6965      0.055    -30.592      0.000      -1.807      -1.586\n",
       "==============================================================================\n",
       "Omnibus:                        5.661   Durbin-Watson:                   2.396\n",
       "Prob(Omnibus):                  0.059   Jarque-Bera (JB):                6.414\n",
       "Skew:                           0.321   Prob(JB):                       0.0405\n",
       "Kurtosis:                       4.373   Cond. No.                         291.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the independent and the dependent variables\n",
    "y = np.log(df['Odds'])\n",
    "X = np.tri(len(y))\n",
    "X = np.cumsum(X, axis=0)[:, 1:]\n",
    "\n",
    "# create lasso instance\n",
    "lics = LassoICSelector(X, y.values, 'bic')\n",
    "\n",
    "# fit\n",
    "lics.fit_best_alpha(X, y)\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lics.lasso.alphas_, lics.criterions_)\n",
    "plt.scatter(lics.lasso.alphas_, lics.criterions_)\n",
    "plt.vlines(lics.lasso.alpha, min(lics.criterions_), max(lics.criterions_))\n",
    "plt.title('alpha={}'.format(lics.lasso.alpha))\n",
    "plt.ylabel('AIC')\n",
    "plt.xlabel('Alpha')\n",
    "plt.xscale('log')\n",
    "\n",
    "lics.ols_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets copy the fitted values to a dataframe, and calculate the parameters and erros of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>R_l</th>\n",
       "      <th>R_u</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-15</th>\n",
       "      <td>2.023348</td>\n",
       "      <td>1.879500</td>\n",
       "      <td>2.167195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-23</th>\n",
       "      <td>1.534846</td>\n",
       "      <td>1.408410</td>\n",
       "      <td>1.661282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>0.736977</td>\n",
       "      <td>0.690962</td>\n",
       "      <td>0.782991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-14</th>\n",
       "      <td>0.485953</td>\n",
       "      <td>0.467988</td>\n",
       "      <td>0.503918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   R       R_l       R_u\n",
       "date                                    \n",
       "2020-03-15  2.023348  1.879500  2.167195\n",
       "2020-03-23  1.534846  1.408410  1.661282\n",
       "2020-03-30  0.736977  0.690962  0.782991\n",
       "2020-04-14  0.485953  0.467988  0.503918"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = df.copy()\n",
    "\n",
    "yhat = lics.ols_results.fittedvalues\n",
    "\n",
    "# from equation 5\n",
    "odds_hat = np.exp(yhat)\n",
    "\n",
    "# the error in yhat is\n",
    "Xols = lics.transform_to_ols(X)\n",
    "(yhat_std, yhat_l, yhat_u) = wls_prediction_std(lics.ols_results, Xols)\n",
    "\n",
    "# propagation of errors\n",
    "oddshat_std = odds_hat*yhat_std\n",
    "\n",
    "data.loc[:, 'odds_hat'] = odds_hat\n",
    "data.loc[:, 'oddshat_std'] = oddshat_std\n",
    "data.loc[:, 'oddshat_l'] = odds_hat - 2*oddshat_std\n",
    "data.loc[:, 'oddshat_u'] = odds_hat + 2*oddshat_std\n",
    "\n",
    "# use coefficients to calculate Rt\n",
    "coef = np.zeros(len(data))\n",
    "coef_std = np.zeros_like(coef) * np.nan\n",
    "ind = np.squeeze(np.argwhere(lics.support))\n",
    "\n",
    "# we do not use the last coefficient since it's the intercept (=log(odds_0))\n",
    "coef[ind] = lics.ols_results.params[:-1]\n",
    "\n",
    "# using equation 2, 4 and 6\n",
    "data.loc[:, 'R'] = np.cumsum(coef)/GAMMA+1\n",
    "\n",
    "# get covarinace matrix of coefficients\n",
    "cov = lics.ols_results.cov_params().values\n",
    "\n",
    "# since the values of Rts are a sum of variables, we use the formula \n",
    "# of the sum of gaussian variables with a known covariance matrix \n",
    "stds = [np.sqrt(cov[:n, :n].sum()) for n in range(1, cov.shape[0])]\n",
    "\n",
    "coef_std[ind] = stds\n",
    "\n",
    "# error propagation formula\n",
    "data.loc[:, 'Rstd'] = coef_std / GAMMA\n",
    "\n",
    "data['Rstd'] = data['Rstd'].fillna(method='ffill')\n",
    "data['R_l'] = data['R'] - 2*data['Rstd']\n",
    "data['R_u'] = data['R'] + 2*data['Rstd']\n",
    "\n",
    "r_index = data.R.diff() != 0\n",
    "Rts = data.loc[r_index, ['R', 'R_l', 'R_u']]\n",
    "display(Rts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we plot the Rt as function of time and the fitted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9465dfb93d452b8ea4257f56980e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8bd639e01b4ac8a3e02b53e285a3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "\n",
    "ax = data.plot(x='Date', y='R', legend=False)\n",
    "ax.fill_between(data.index, data['R_u'], data['R_l'],\n",
    "                facecolor='blue', alpha=0.2, label='95% CI')\n",
    "ax.vlines(events, 0, data.R_u.max())\n",
    "\n",
    "plt.ylabel('Rt')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/RtL1.jpg', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.scatterplot(x='Date', y='Odds', data=data, label='Data')\n",
    "ax = sns.lineplot(x='Date', y='odds_hat', label='Fit', ax=ax, data=data)\n",
    "ax.fill_between(data.index, data['oddshat_l'],\n",
    "                data['oddshat_u'],\n",
    "                facecolor='blue', alpha=0.1, label='95% CI')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.ylabel('Odds')\n",
    "plt.tight_layout()\n",
    "ax.set_xlim(data['Date'].min(), data['Date'].max())\n",
    "plt.savefig('figs/OddsL1.jpg', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counterfactual (what if)\n",
    "\n",
    "1. What if the final step in Rt had not happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f0b1b689a04342a907f1480841cbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fitted_params = lics.ols_results.params.copy()\n",
    "current_palette = sns.color_palette()\n",
    "\n",
    "i = 3\n",
    "\n",
    "params_cf = lics.ols_results.params.copy()\n",
    "params_cf[i] = 0\n",
    "lics.ols_results.params = params_cf\n",
    "yhat = lics.predict(lics.transform_to_ols(X))\n",
    "odds_cf = np.exp(yhat)\n",
    "(yhat_std, yhat_l, yhat_u) = wls_prediction_std(lics.ols_results, lics.transform_to_ols(X))\n",
    "oddshat_std = odds_cf*yhat_std\n",
    "\n",
    "lics.ols_results.params = fitted_params\n",
    "ratio_cf = odds_cf / (odds_cf+1)\n",
    "\n",
    "coef = np.zeros(len(data))\n",
    "ind = np.squeeze(np.argwhere(lics.support))\n",
    "coef[ind] = params_cf[:-1]\n",
    "data['R_cf_{}'.format(i)] = np.cumsum(coef)/GAMMA+1\n",
    "\n",
    "data['Odds CF {}'.format(i)] = odds_cf\n",
    "\n",
    "data['oddshat_l_cf_{}'.format(i)] = odds_cf - 2*oddshat_std\n",
    "data['oddshat_u_cf_{}'.format(i)] = odds_cf + 2*oddshat_std\n",
    "\n",
    "data['ratio_cf_{}'.format(i)] = ratio_cf\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.scatterplot(x='Date', y='Odds', data=data, label='Data', c=np.array([current_palette[0]]))\n",
    "\n",
    "ax = sns.lineplot(x='Date', y='odds_hat', data=data, ax=ax, palette=[current_palette[i]], label='Fit')\n",
    "ax.fill_between(data.index, data['oddshat_l'],\n",
    "                data['oddshat_u'],\n",
    "                alpha=0.1)\n",
    "\n",
    "ax = sns.lineplot(x='Date', y='Odds CF {}'.format(i), data=data, ax=ax, palette=[current_palette[i]], label='Counterfactual No Masks')\n",
    "ax.fill_between(data.index, data['oddshat_l_cf_{}'.format(i)],\n",
    "                data['oddshat_u_cf_{}'.format(i)],\n",
    "                alpha=0.1)\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "plt.grid(True)\n",
    "plt.ylabel('Odds')\n",
    "ax.set_xlim(data['Date'].min(), data.loc[data.odds_hat.notna(), 'Date'].max())\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/odds_cf_masks.jpg', dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342a7c4b3dc1468aad7d074d31d654b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (1.0, 0.4980392156862745, 0.054901960784313725)\n",
      "1 (1.0, 0.4980392156862745, 0.054901960784313725)\n",
      "2 (0.17254901960784313, 0.6274509803921569, 0.17254901960784313)\n",
      "2 (0.17254901960784313, 0.6274509803921569, 0.17254901960784313)\n",
      "3 (0.8392156862745098, 0.15294117647058825, 0.1568627450980392)\n",
      "3 (0.8392156862745098, 0.15294117647058825, 0.1568627450980392)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a359f54c5f82422facaf2b34f1c5f106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fitted_params = lics.ols_results.params.copy()\n",
    "current_palette = sns.color_palette()\n",
    "for i in range(1, 4):\n",
    "    params_cf = lics.ols_results.params.copy()\n",
    "    params_cf[i] = 0\n",
    "    lics.ols_results.params = params_cf\n",
    "    yhat = lics.predict(lics.transform_to_ols(X))\n",
    "    odds_cf = np.exp(yhat)\n",
    "    (yhat_std, yhat_l, yhat_u) = wls_prediction_std(lics.ols_results, lics.transform_to_ols(X))\n",
    "    oddshat_std = odds_cf*yhat_std\n",
    "\n",
    "    lics.ols_results.params = fitted_params\n",
    "    ratio_cf = odds_cf / (odds_cf+1)\n",
    "\n",
    "    coef = np.zeros(len(data))\n",
    "    ind = np.squeeze(np.argwhere(lics.support))\n",
    "    coef[ind] = params_cf[:-1]\n",
    "    data['R_cf_{}'.format(i)] = np.cumsum(coef)/GAMMA+1\n",
    "\n",
    "    data['Odds CF {}'.format(i)] = odds_cf\n",
    "\n",
    "    data['oddshat_l_cf_{}'.format(i)] = odds_cf - 2*oddshat_std\n",
    "    data['oddshat_u_cf_{}'.format(i)] = odds_cf + 2*oddshat_std\n",
    "\n",
    "    data['ratio_cf_{}'.format(i)] = ratio_cf\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.scatterplot(x='Date', y='Odds', data=data, label='Data', c=np.array([current_palette[0]]))\n",
    "for i in range(1, 4):\n",
    "    print(i, current_palette[i])\n",
    "    ax = sns.lineplot(x='Date', y='Odds CF {}'.format(i), data=data, ax=ax, palette=[current_palette[i]], label='Odds CF {}'.format(i))\n",
    "    print(i, current_palette[i])\n",
    "    ax.fill_between(data.index, data['oddshat_l_cf_{}'.format(i)],\n",
    "                    data['oddshat_u_cf_{}'.format(i)],\n",
    "                    alpha=0.1)\n",
    "\n",
    "plt.yscale('log')\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "plt.grid(True)\n",
    "plt.ylabel('Odds')\n",
    "ax.set_xlim(data['Date'].min(), data.loc[data.odds_hat.notna(), 'Date'].max())\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/odds_cf.jpg')\n",
    "plt.show()\n",
    "\n",
    "data.plot(y=['R', 'R_cf_1', 'R_cf_2', 'R_cf_3'], grid=True)\n",
    "plt.savefig('figs/R_cf.png')\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-15 00:00:00 2020-03-31 00:00:00 2020-04-13 00:00:00 2020-05-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "n = 22\n",
    "\n",
    "Xf = np.repeat([np.arange(1, X.shape[1]+1)[::-1]], n, axis=0)\n",
    "Xf += np.arange(n).reshape(n, 1)\n",
    "Xf = lics.transform_to_ols(Xf)\n",
    "yhat_extrapolation = lics.ols.predict(lics.ols_results.params, Xf)\n",
    "odds_hat_extrapolation = np.exp(yhat_extrapolation)\n",
    "(yhat_std, yhat_l, yhat_u) = wls_prediction_std(lics.ols_results, Xf)\n",
    "oddshat_std = odds_hat_extrapolation*yhat_std\n",
    "extrapolation = pd.DataFrame({'oddshat_extrapolation_std': oddshat_std,\n",
    "                              'odds_hat_extrapolation': odds_hat_extrapolation\n",
    "                              },\n",
    "                             index=data.index.shift(n-1, freq='D')[-n:])\n",
    "extrapolation = pd.merge(data, extrapolation, how='outer', left_index=True,\n",
    "                right_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
